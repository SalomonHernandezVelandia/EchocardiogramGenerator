{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f22FzMDqNUGL",
        "outputId": "8d46b047-d200-475e-bb60-af1cec6d7cd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-06553bef-ead0-c4fb-1080-5982f2b3cce4)\n"
          ]
        }
      ],
      "source": [
        "# Verificar GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW5bwV17N4oy",
        "outputId": "0bc86934-d2c1-4520-d883-1b076648bf45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2TXIzZrPUjea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependencias necesarias\n",
        "repo_dir = \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch\"\n",
        "data_dir = \"/content/drive/MyDrive/Proyecto_Grado/Data\""
      ],
      "metadata": {
        "id": "0tXlRW1Wkzbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependencias necesarias\n",
        "repo_dir = \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch\"\n",
        "data_dir = \"/content/drive/MyDrive/Proyecto_Grado/Data\"\n",
        "\n",
        "# Clona si no existe\n",
        "if not os.path.isdir(repo_dir):\n",
        "    %cd /content/drive/MyDrive/Proyecto_Grado/\n",
        "    !git clone https://github.com/dvschultz/stylegan2-ada-pytorch colab-sg2-ada-pytorch\n",
        "    %cd colab-sg2-ada-pytorch\n",
        "    !mkdir datasets downloads pretrained\n",
        "    # Puedes omitir esta lÃ­nea si no necesitas el modelo wikiart.pkl\n",
        "    # !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU -O pretrained/wikiart.pkl\n",
        "\n",
        "# Cambiar al repo\n",
        "%cd {repo_dir}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls6uI9mfN5oM",
        "outputId": "d3f5d0df-84e1-467f-a2ce-ed1a015ae743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependencias especÃ­ficas\n",
        "!pip install gdown --upgrade\n",
        "!pip uninstall -y jax jaxlib\n",
        "!pip install \"jax[cuda11_cudnn805]==0.3.10\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install timm==0.4.12 ftfy==6.1.1 ninja==1.10.2 opensimplex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSjT3xlCOiqO",
        "outputId": "a80651cd-5380-41b8-a630-58fccacef476",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Found existing installation: jax 0.5.3\n",
            "Uninstalling jax-0.5.3:\n",
            "  Successfully uninstalled jax-0.5.3\n",
            "Found existing installation: jaxlib 0.5.3\n",
            "Uninstalling jaxlib-0.5.3:\n",
            "  Successfully uninstalled jaxlib-0.5.3\n",
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Collecting jax==0.3.10 (from jax[cuda11_cudnn805]==0.3.10)\n",
            "  Downloading jax-0.3.10.tar.gz (939 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from jax==0.3.10->jax[cuda11_cudnn805]==0.3.10) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.12/dist-packages (from jax==0.3.10->jax[cuda11_cudnn805]==0.3.10) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax==0.3.10->jax[cuda11_cudnn805]==0.3.10) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from jax==0.3.10->jax[cuda11_cudnn805]==0.3.10) (1.16.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from jax==0.3.10->jax[cuda11_cudnn805]==0.3.10) (4.14.1)\n",
            "INFO: pip is looking at multiple versions of jax[cuda11-cudnn805] to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 0.4.32\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement jaxlib==0.3.10+cuda11.cudnn805; extra == \"cuda11-cudnn805\" (from jax[cuda11-cudnn805]) (from versions: 0.4.17, 0.4.17+cuda11.cudnn86, 0.4.17+cuda12.cudnn89, 0.4.18, 0.4.18+cuda11.cudnn86, 0.4.18+cuda12.cudnn89, 0.4.19, 0.4.19+cuda11.cudnn86, 0.4.19+cuda12.cudnn89, 0.4.20, 0.4.20+cuda11.cudnn86, 0.4.20+cuda12.cudnn89, 0.4.21, 0.4.21+cuda11.cudnn86, 0.4.21+cuda12.cudnn89, 0.4.22, 0.4.22+cuda11.cudnn86, 0.4.22+cuda12.cudnn89, 0.4.23, 0.4.23+cuda11.cudnn86, 0.4.23+cuda12.cudnn89, 0.4.24, 0.4.24+cuda11.cudnn86, 0.4.24+cuda12.cudnn89, 0.4.25, 0.4.25+cuda11.cudnn86, 0.4.25+cuda12.cudnn89, 0.4.26, 0.4.26+cuda12.cudnn89, 0.4.27, 0.4.27+cuda12.cudnn89, 0.4.28, 0.4.28+cuda12.cudnn89, 0.4.29, 0.4.29+cuda12.cudnn91, 0.4.30, 0.4.31, 0.4.33, 0.4.34, 0.4.35, 0.4.36, 0.4.38, 0.5.0, 0.5.1, 0.5.3, 0.6.0, 0.6.1, 0.6.2, 0.7.0, 0.7.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for jaxlib==0.3.10+cuda11.cudnn805; extra == \"cuda11-cudnn805\"\u001b[0m\u001b[31m\n",
            "\u001b[0mFound existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Successfully uninstalled torch-2.8.0+cu126\n",
            "Found existing installation: torchvision 0.23.0+cu126\n",
            "Uninstalling torchvision-0.23.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.23.0+cu126\n",
            "Found existing installation: torchaudio 2.8.0+cu126\n",
            "Uninstalling torchaudio-2.8.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.0+cu111 (from versions: 2.2.0, 2.2.0+cpu, 2.2.0+cpu.cxx11.abi, 2.2.0+cu118, 2.2.0+cu121, 2.2.0+rocm5.6, 2.2.0+rocm5.7, 2.2.1, 2.2.1+cpu, 2.2.1+cpu.cxx11.abi, 2.2.1+cu118, 2.2.1+cu121, 2.2.1+rocm5.6, 2.2.1+rocm5.7, 2.2.2, 2.2.2+cpu, 2.2.2+cpu.cxx11.abi, 2.2.2+cu118, 2.2.2+cu121, 2.2.2+rocm5.6, 2.2.2+rocm5.7, 2.3.0, 2.3.0+cpu, 2.3.0+cpu.cxx11.abi, 2.3.0+cu118, 2.3.0+cu121, 2.3.0+rocm5.7, 2.3.0+rocm6.0, 2.3.1, 2.3.1+cpu, 2.3.1+cpu.cxx11.abi, 2.3.1+cu118, 2.3.1+cu121, 2.3.1+rocm5.7, 2.3.1+rocm6.0, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.0+cu111\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting timm==0.4.12\n",
            "  Downloading timm-0.4.12-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting ftfy==6.1.1\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting ninja==1.10.2\n",
            "  Downloading ninja-1.10.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting opensimplex\n",
            "  Downloading opensimplex-0.4.5.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting torch>=1.4 (from timm==0.4.12)\n",
            "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchvision (from timm==0.4.12)\n",
            "  Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.12/dist-packages (from ftfy==6.1.1) (0.2.13)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from opensimplex) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.4->timm==0.4.12)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.4->timm==0.4.12)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.4->timm==0.4.12)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.4->timm==0.4.12)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.4->timm==0.4.12)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.4->timm==0.4.12)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.4->timm==0.4.12)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.4->timm==0.4.12)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12) (2.27.3)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.4->timm==0.4.12)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.4->timm==0.4.12)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.4->timm==0.4.12)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->timm==0.4.12) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm==0.4.12) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.4->timm==0.4.12) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.4->timm==0.4.12) (3.0.2)\n",
            "Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.10.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108.1/108.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opensimplex-0.4.5.1-py3-none-any.whl (267 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.0/268.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja, opensimplex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, torchvision, timm\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.19\n",
            "    Uninstalling timm-1.0.19:\n",
            "      Successfully uninstalled timm-1.0.19\n",
            "Successfully installed ftfy-6.1.1 ninja-1.10.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 opensimplex-0.4.5.1 timm-0.4.12 torch-2.8.0 torchvision-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "XDwz7D4eOxFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET\n",
        "dataset_zip = f\"{data_dir}/frames_extraidos.zip\"\n",
        "results_dir = f\"{repo_dir}/resultsE2\"\n",
        "progreso_dir = f\"{repo_dir}/progresoE2\"\n",
        "os.makedirs(progreso_dir, exist_ok=True)\n",
        "\n",
        "# Buscar Ãºltimo snapshot\n",
        "snapshots = sorted(glob.glob(f'{results_dir}/0*/network-snapshot-*.pkl'))\n",
        "resume_path = snapshots[-1] if snapshots else None\n",
        "\n",
        "usar_snapshot = True  # Cambia a False si quieres entrenar desde cero\n",
        "\n",
        "if usar_snapshot and resume_path:\n",
        "    print(f\"Reanudando entrenamiento desde: {resume_path}\")\n",
        "    resume_flag = f\"--resume={resume_path}\"\n",
        "else:\n",
        "    print(\"Iniciando entrenamiento desde cero\")\n",
        "    resume_flag = \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYPV4tWmU5Fr",
        "outputId": "8679e93e-8011-4071-9ca8-b957bb38f263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reanudando entrenamiento desde: /content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/resultsE2/00004-frames_extraidos-11gb-gpu-gamma32-batch32-ada-target0.6-resumecustom/network-snapshot-000096.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "!python train.py \\\n",
        "  --outdir={results_dir} \\\n",
        "  --data={dataset_zip} \\\n",
        "  --gpus=1 \\\n",
        "  --batch=32 \\\n",
        "  --cfg=11gb-gpu \\\n",
        "  --mirror=0 \\\n",
        "  --gamma=32 \\\n",
        "  --aug=ada \\\n",
        "  --target=0.6 \\\n",
        "  --lrate=0.006 \\\n",
        "  --snap=4 \\\n",
        "  {\"--resume=\" + resume_path if resume_path else \"\"}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1m_LCIQOypQ",
        "outputId": "71cdb5e3-b7c0-4fb5-f04e-ec7e418ace62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 4,\n",
            "  \"network_snapshot_ticks\": 4,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/Proyecto_Grado/Data/frames_extraidos.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 40120,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 128\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 8\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 32768,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.006,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.006,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 32.0\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 32,\n",
            "  \"ema_kimg\": 10,\n",
            "  \"ema_rampup\": null,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/resultsE2/00004-frames_extraidos-11gb-gpu-gamma32-batch32-ada-target0.6-resumecustom/network-snapshot-000096.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/resultsE2/00005-frames_extraidos-11gb-gpu-gamma32-batch32-ada-target0.6-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/resultsE2/00005-frames_extraidos-11gb-gpu-gamma32-batch32-ada-target0.6-resumecustom\n",
            "Training data:      /content/drive/MyDrive/Proyecto_Grado/Data/frames_extraidos.zip\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   40120\n",
            "Image resolution:   128\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/sampler.py:68: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n",
            "Num images:  40120\n",
            "Image shape: [1, 128, 128]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "starting G epochs:  0.0\n",
            "Resuming from \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/resultsE2/00004-frames_extraidos-11gb-gpu-gamma32-batch32-ada-target0.6-resumecustom/network-snapshot-000096.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... W0820 22:28:53.182000 1759 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "W0820 22:28:53.182000 1759 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n",
            "Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... W0820 22:29:21.626000 1759 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "W0820 22:29:21.626000 1759 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n",
            "Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           262656      -        [32, 512]            float32 \n",
            "mapping.fc1           262656      -        [32, 512]            float32 \n",
            "mapping.fc2           262656      -        [32, 512]            float32 \n",
            "mapping.fc3           262656      -        [32, 512]            float32 \n",
            "mapping.fc4           262656      -        [32, 512]            float32 \n",
            "mapping.fc5           262656      -        [32, 512]            float32 \n",
            "mapping.fc6           262656      -        [32, 512]            float32 \n",
            "mapping.fc7           262656      -        [32, 512]            float32 \n",
            "mapping               -           512      [32, 12, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [32, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    263169      -        [32, 1, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [32, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [32, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [32, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [32, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    263169      -        [32, 1, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [32, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [32, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [32, 512, 16, 16]    float16 \n",
            "synthesis.b16.conv1   2622465     272      [32, 512, 16, 16]    float16 \n",
            "synthesis.b16.torgb   263169      -        [32, 1, 16, 16]      float16 \n",
            "synthesis.b16:0       -           16       [32, 512, 16, 16]    float16 \n",
            "synthesis.b16:1       -           -        [32, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [32, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [32, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   263169      -        [32, 1, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [32, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [32, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   2622465     4112     [32, 512, 64, 64]    float16 \n",
            "synthesis.b64.conv1   2622465     4112     [32, 512, 64, 64]    float16 \n",
            "synthesis.b64.torgb   263169      -        [32, 1, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [32, 512, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [32, 512, 64, 64]    float32 \n",
            "synthesis.b128.conv0  1442561     16400    [32, 256, 128, 128]  float16 \n",
            "synthesis.b128.conv1  721409      16400    [32, 256, 128, 128]  float16 \n",
            "synthesis.b128.torgb  131585      -        [32, 1, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [32, 256, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [32, 256, 128, 128]  float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 29323025    44448    -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b128.fromrgb   512         16       [32, 256, 128, 128]  float16 \n",
            "b128.skip      131072      16       [32, 512, 64, 64]    float16 \n",
            "b128.conv0     590080      16       [32, 256, 128, 128]  float16 \n",
            "b128.conv1     1180160     16       [32, 512, 64, 64]    float16 \n",
            "b128           -           16       [32, 512, 64, 64]    float16 \n",
            "b64.skip       262144      16       [32, 512, 32, 32]    float16 \n",
            "b64.conv0      2359808     16       [32, 512, 64, 64]    float16 \n",
            "b64.conv1      2359808     16       [32, 512, 32, 32]    float16 \n",
            "b64            -           16       [32, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [32, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [32, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [32, 512, 16, 16]    float16 \n",
            "b32            -           16       [32, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [32, 512, 8, 8]      float16 \n",
            "b16.conv0      2359808     16       [32, 512, 16, 16]    float16 \n",
            "b16.conv1      2359808     16       [32, 512, 8, 8]      float16 \n",
            "b16            -           16       [32, 512, 8, 8]      float16 \n",
            "b8.skip        262144      16       [32, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [32, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [32, 512, 4, 4]      float32 \n",
            "b8             -           16       [32, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [32, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [32, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [32, 512]            float32 \n",
            "b4.out         513         -        [32, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          28388609    352      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2025-08-20 22:30:19.486114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755729019.760000    1759 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755729019.832971    1759 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755729020.414491    1759 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755729020.414524    1759 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755729020.414529    1759 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755729020.414534    1759 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-20 22:30:20.469939: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 2m 45s       sec/tick 50.5    sec/kimg 1579.37 maintenance 114.0  cpumem 3.11   gpumem 12.13  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "{\"results\": {\"fid50k_full\": 93.2092553284397}, \"metric\": \"fid50k_full\", \"total_time\": 861.3005149364471, \"total_time_str\": \"14m 21s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1755729946.3907156}\n",
            "tick 1     kimg 4.0      time 22m 10s      sec/tick 294.3   sec/kimg 73.59   maintenance 871.0  cpumem 3.60   gpumem 10.40  augment 0.000\n",
            "tick 2     kimg 8.0      time 27m 06s      sec/tick 295.2   sec/kimg 73.81   maintenance 0.4    cpumem 3.60   gpumem 8.56   augment 0.000\n",
            "tick 3     kimg 12.0     time 32m 01s      sec/tick 295.0   sec/kimg 73.75   maintenance 0.4    cpumem 3.60   gpumem 8.56   augment 0.000\n",
            "tick 4     kimg 16.0     time 36m 56s      sec/tick 295.5   sec/kimg 73.87   maintenance 0.0    cpumem 3.60   gpumem 8.56   augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 69.98283145304548}, \"metric\": \"fid50k_full\", \"total_time\": 656.2962737083435, \"total_time_str\": \"10m 56s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000016.pkl\", \"timestamp\": 1755731796.417129}\n",
            "tick 5     kimg 20.0     time 53m 00s      sec/tick 294.6   sec/kimg 73.66   maintenance 669.1  cpumem 3.57   gpumem 8.56   augment 0.000\n",
            "tick 6     kimg 24.0     time 57m 55s      sec/tick 294.5   sec/kimg 73.63   maintenance 0.4    cpumem 3.57   gpumem 8.56   augment 0.000\n",
            "tick 7     kimg 28.0     time 1h 02m 51s   sec/tick 296.0   sec/kimg 74.00   maintenance 0.4    cpumem 3.57   gpumem 8.56   augment 0.000\n",
            "tick 8     kimg 32.0     time 1h 07m 47s   sec/tick 295.9   sec/kimg 73.98   maintenance 0.0    cpumem 3.57   gpumem 8.56   augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 68.64059766148452}, \"metric\": \"fid50k_full\", \"total_time\": 655.3164894580841, \"total_time_str\": \"10m 55s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000032.pkl\", \"timestamp\": 1755733649.2750516}\n",
            "tick 9     kimg 36.0     time 1h 23m 54s   sec/tick 295.7   sec/kimg 73.93   maintenance 671.0  cpumem 3.61   gpumem 8.56   augment 0.001\n",
            "tick 10    kimg 40.0     time 1h 28m 50s   sec/tick 295.9   sec/kimg 73.97   maintenance 0.4    cpumem 3.61   gpumem 8.56   augment 0.000\n",
            "tick 11    kimg 44.0     time 1h 33m 46s   sec/tick 295.1   sec/kimg 73.79   maintenance 0.4    cpumem 3.61   gpumem 8.56   augment 0.000\n",
            "tick 12    kimg 48.0     time 1h 38m 42s   sec/tick 296.1   sec/kimg 74.03   maintenance 0.0    cpumem 3.61   gpumem 8.56   augment 0.000\n",
            "Evaluating metrics...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CALCULO METRICAS"
      ],
      "metadata": {
        "id": "62TS1tDXPLG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lpips"
      ],
      "metadata": {
        "id": "DA4NprBNPOmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, json, re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import dnnlib\n",
        "import legacy\n",
        "import torchvision.transforms as T\n",
        "import skimage.metrics\n",
        "import lpips\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Definir el dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NscuhoYeRAeD",
        "outputId": "c0811e24-89d2-475e-d660-d96148185d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Claves encontradas: ['Loss/scores/fake', 'Loss/signs/fake', 'Loss/G/loss', 'Loss/pl_penalty', 'Loss/G/reg', 'Loss/scores/real', 'Loss/signs/real', 'Loss/D/loss', 'Loss/r1_penalty', 'Loss/D/reg', 'Progress/tick', 'Progress/kimg', 'Timing/total_sec', 'Timing/sec_per_tick', 'Timing/sec_per_kimg', 'Timing/maintenance_sec', 'Resources/cpu_mem_gb', 'Resources/peak_gpu_mem_gb', 'Progress/augment', 'Timing/total_hours', 'Timing/total_days', 'Timing/Gmain', 'Timing/Greg', 'Timing/Dmain', 'Timing/Dreg', 'timestamp']\n",
            "ğŸ” Claves encontradas: ['Loss/scores/fake', 'Loss/signs/fake', 'Loss/G/loss', 'Loss/pl_penalty', 'Loss/G/reg', 'Loss/scores/real', 'Loss/signs/real', 'Loss/D/loss', 'Loss/r1_penalty', 'Loss/D/reg', 'Progress/tick', 'Progress/kimg', 'Timing/total_sec', 'Timing/sec_per_tick', 'Timing/sec_per_kimg', 'Timing/maintenance_sec', 'Resources/cpu_mem_gb', 'Resources/peak_gpu_mem_gb', 'Progress/augment', 'Timing/total_hours', 'Timing/total_days', 'Timing/Gmain', 'Timing/Greg', 'Timing/Dmain', 'Timing/Dreg', 'timestamp']\n",
            "ğŸ” Claves encontradas: ['Loss/scores/fake', 'Loss/signs/fake', 'Loss/G/loss', 'Loss/pl_penalty', 'Loss/G/reg', 'Loss/scores/real', 'Loss/signs/real', 'Loss/D/loss', 'Loss/r1_penalty', 'Loss/D/reg', 'Progress/tick', 'Progress/kimg', 'Timing/total_sec', 'Timing/sec_per_tick', 'Timing/sec_per_kimg', 'Timing/maintenance_sec', 'Resources/cpu_mem_gb', 'Resources/peak_gpu_mem_gb', 'Progress/augment', 'Timing/total_hours', 'Timing/total_days', 'Timing/Gmain', 'Timing/Greg', 'Timing/Dmain', 'Timing/Dreg', 'timestamp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== KID HELPER ==================\n",
        "# InceptionV3 para FID/KID: usamos el penÃºltimo layer (pool3)\n",
        "inception = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1, transform_input=False)\n",
        "inception.fc = nn.Identity()  # quitamos la Ãºltima capa de clasificaciÃ³n\n",
        "inception.eval().to(device)\n",
        "\n",
        "def get_inception_features(x):\n",
        "    # x debe estar en rango [-1, 1], lo pasamos a [0, 1] si es necesario\n",
        "    if x.min() < 0:\n",
        "        x = (x + 1) / 2\n",
        "    if x.shape[2] != 299 or x.shape[3] != 299:\n",
        "        x = torch.nn.functional.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "    with torch.no_grad():\n",
        "        feats = inception(x)  # ahora devuelve [B,2048]\n",
        "    return feats\n",
        "\n",
        "\n",
        "def polynomial_mmd(x, y, degree=3, gamma=None, coef0=1):\n",
        "    xx = x @ x.t()\n",
        "    yy = y @ y.t()\n",
        "    xy = x @ y.t()\n",
        "    if gamma is None:\n",
        "        gamma = 1.0 / x.shape[1]\n",
        "    K_xx = (gamma * xx + coef0) ** degree\n",
        "    K_yy = (gamma * yy + coef0) ** degree\n",
        "    K_xy = (gamma * xy + coef0) ** degree\n",
        "    return K_xx.mean() + K_yy.mean() - 2 * K_xy.mean()\n",
        "\n",
        "def compute_kid(real_imgs, fake_imgs, batch_size=16):\n",
        "    real_feats, fake_feats = [], []\n",
        "    for i in range(0, len(real_imgs), batch_size):\n",
        "        r = torch.cat(real_imgs[i:i+batch_size]).to(device)\n",
        "        f = torch.cat(fake_imgs[i:i+batch_size]).to(device)\n",
        "        real_feats.append(get_inception_features(r))\n",
        "        fake_feats.append(get_inception_features(f))\n",
        "    real_feats = torch.cat(real_feats, dim=0)\n",
        "    fake_feats = torch.cat(fake_feats, dim=0)\n",
        "    return polynomial_mmd(real_feats, fake_feats).item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5orT-FyJO4qG",
        "outputId": "885589bd-6981-495a-8d99-e18ca1acf27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV combinado guardado en: /content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/progreso/losses_all_runs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === PPL helper ===\n",
        "def compute_ppl(G, device, n_samples=64, eps=1e-4):\n",
        "    lat_dim = G.z_dim\n",
        "    z = torch.randn([n_samples, lat_dim], device=device)\n",
        "    c = torch.zeros([n_samples, G.c_dim], device=device)\n",
        "\n",
        "    # InterpolaciÃ³n en el espacio latente\n",
        "    z_eps = z.clone()\n",
        "    z_eps[:, 0] += eps  # perturbamos la primera dimensiÃ³n del vector z\n",
        "\n",
        "    # Generar imÃ¡genes originales y perturbadas\n",
        "    imgs1 = G(z, c, truncation_psi=0.7, noise_mode='const')\n",
        "    imgs2 = G(z_eps, c, truncation_psi=0.7, noise_mode='const')\n",
        "\n",
        "    # Normalizamos [0,1] para LPIPS\n",
        "    imgs1 = (imgs1.clamp(-1, 1) + 1) / 2\n",
        "    imgs2 = (imgs2.clamp(-1, 1) + 1) / 2\n",
        "\n",
        "    # Redimensionamos a 256x256 para LPIPS (mÃ¡s rÃ¡pido)\n",
        "    imgs1 = torch.nn.functional.interpolate(imgs1, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "    imgs2 = torch.nn.functional.interpolate(imgs2, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "\n",
        "    # LPIPS perceptual distance\n",
        "    lpips_model = lpips.LPIPS(net='alex').to(device)\n",
        "    d = lpips_model(imgs1, imgs2)\n",
        "\n",
        "    # Escalamos por la perturbaciÃ³n\n",
        "    ppl = (d / (eps**2)).mean().item()\n",
        "    return ppl"
      ],
      "metadata": {
        "id": "OVYL6jCVVeT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92df3043-d059-4a20-9550-8de129f82769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00000-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32] MÃ©tricas guardadas para 0kimg\n",
            "[00000-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32] MÃ©tricas guardadas para 16kimg\n",
            "[00000-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32] MÃ©tricas guardadas para 32kimg\n",
            "[00000-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32] MÃ©tricas guardadas para 48kimg\n",
            "[00000-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32] MÃ©tricas guardadas para 80kimg\n",
            "[00000-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32] MÃ©tricas guardadas para 96kimg\n",
            "[00001-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32-resumecustom] MÃ©tricas guardadas para 0kimg\n",
            "[00001-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32-resumecustom] MÃ©tricas guardadas para 16kimg\n",
            "[00001-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32-resumecustom] MÃ©tricas guardadas para 48kimg\n",
            "[00001-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32-resumecustom] MÃ©tricas guardadas para 64kimg\n",
            "[00001-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32-resumecustom] MÃ©tricas guardadas para 80kimg\n",
            "[00001-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32-resumecustom] MÃ©tricas guardadas para 112kimg\n",
            "[00002-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32-resumecustom] MÃ©tricas guardadas para 0kimg\n",
            "[00002-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32-resumecustom] MÃ©tricas guardadas para 16kimg\n",
            "[00002-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32-resumecustom] MÃ©tricas guardadas para 32kimg\n",
            "[00002-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32-resumecustom] MÃ©tricas guardadas para 48kimg\n",
            "[00002-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32-resumecustom] MÃ©tricas guardadas para 96kimg\n",
            "[00002-1erFramesVideosMEDGAN-11gb-gpu-gamma50-batch32-resumecustom] MÃ©tricas guardadas para 112kimg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== CONFIGURACIÃ“N ==================\n",
        "# Dataset\n",
        "N_images = 40120\n",
        "mirror = 0          # 1 si usaste --mirror=1, 0 si no\n",
        "N_eff = N_images * (2 if mirror == 1 else 1)\n",
        "\n",
        "# Paths\n",
        "results_dir = \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/resultsE2\"\n",
        "progreso_dir = \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/progresoE2\"\n",
        "data_dir = \"/content/drive/MyDrive/Proyecto_Grado/Data\"\n",
        "os.makedirs(progreso_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Imagen real (ejemplo: primera de class0)\n",
        "real_image_path = sorted(glob.glob(f'{data_dir}/frames_extraidos/*.png'))[0]\n",
        "target_size = (512, 512)\n",
        "\n",
        "# TransformaciÃ³n\n",
        "real_img = Image.open(real_image_path).convert('RGB').resize(target_size)\n",
        "transform = T.ToTensor()\n",
        "x_real = transform(real_img).numpy()\n",
        "\n",
        "# CSV final\n",
        "out_csv = os.path.join(progreso_dir, \"metrics_snapshots.csv\")\n",
        "\n",
        "# ================== MÃ‰TRICAS ==================\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# LPIPS\n",
        "loss_fn_lpips = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "# JSD helper\n",
        "def compute_jsd(p, q, bins=256):\n",
        "    p_hist, _ = np.histogram(p.flatten(), bins=bins, range=(0,1), density=True)\n",
        "    q_hist, _ = np.histogram(q.flatten(), bins=bins, range=(0,1), density=True)\n",
        "    return jensenshannon(p_hist, q_hist)\n",
        "\n",
        "# ================== LOOP PRINCIPAL ==================\n",
        "all_rows = []\n",
        "run_dirs = sorted(glob.glob(f'{results_dir}/0000*'))\n",
        "\n",
        "kimg_offset = 0  # <<< offset acumulativo de kimgs\n",
        "\n",
        "for run_dir in run_dirs:\n",
        "    run_id = os.path.basename(run_dir)\n",
        "\n",
        "    # ---- Cargar stats.jsonl para pÃ©rdidas ----\n",
        "    stats_path = os.path.join(run_dir, 'stats.jsonl')\n",
        "    stats_lines = []\n",
        "    if os.path.exists(stats_path):\n",
        "        with open(stats_path, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    e = json.loads(line)\n",
        "                    kimg_val = e['Progress/kimg']['mean'] if isinstance(e['Progress/kimg'], dict) else e['Progress/kimg']\n",
        "                    g_loss = e['Loss/G/loss']['mean'] if isinstance(e['Loss/G/loss'], dict) else e['Loss/G/loss']\n",
        "                    d_loss = e['Loss/D/loss']['mean'] if isinstance(e['Loss/D/loss'], dict) else e['Loss/D/loss']\n",
        "                    stats_lines.append((float(kimg_val), g_loss, d_loss))\n",
        "                except KeyError:\n",
        "                    continue\n",
        "\n",
        "    # ---- Cargar metric-fid50k_full.jsonl ----\n",
        "    fid_dict = {}\n",
        "    fid_path = os.path.join(run_dir, \"metric-fid50k_full.jsonl\")\n",
        "    if os.path.exists(fid_path):\n",
        "        with open(fid_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    e = json.loads(line)\n",
        "                    snap = os.path.basename(e[\"snapshot_pkl\"])\n",
        "                    fid = e[\"results\"][\"fid50k_full\"]\n",
        "                    fid_dict[snap] = fid\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    # ---- Buscar snapshots ----\n",
        "    snapshot_paths = sorted(glob.glob(f'{run_dir}/network-snapshot-*.pkl'))\n",
        "\n",
        "    for snapshot in snapshot_paths:\n",
        "        snap_name = os.path.basename(snapshot)\n",
        "        kimg_match = re.search(r'network-snapshot-(\\d+).pkl', snapshot)\n",
        "        if not kimg_match:\n",
        "            continue\n",
        "        kimg_snap_local = int(kimg_match.group(1))  # kimg relativo a la carpeta\n",
        "        kimg_snap = kimg_snap_local + kimg_offset   # kimg absoluto y continuo\n",
        "        epoch = (kimg_snap * 1000) / N_eff          # conversiÃ³n a Ã©pocas\n",
        "\n",
        "        # Buscar pÃ©rdidas en stats.jsonl para este kimg local\n",
        "        g_loss, d_loss = None, None\n",
        "        if stats_lines:\n",
        "            nearest = min(stats_lines, key=lambda x: abs(x[0] - kimg_snap_local))\n",
        "            g_loss, d_loss = nearest[1], nearest[2]\n",
        "\n",
        "        # === Generar imagen con el snapshot ===\n",
        "        with dnnlib.util.open_url(snapshot) as f_model:\n",
        "            G = legacy.load_network_pkl(f_model)['G_ema'].to(device)\n",
        "\n",
        "        z = torch.randn([1, G.z_dim], device=device)\n",
        "        label = torch.zeros([1, G.c_dim], device=device)\n",
        "        img = G(z, label, truncation_psi=0.7, noise_mode='const')\n",
        "\n",
        "        img = (img.clamp(-1, 1) + 1) * 127.5\n",
        "        img = img.permute(0, 2, 3, 1)[0].cpu().numpy().astype(np.uint8)\n",
        "        if img.shape[-1] == 1:\n",
        "            img = np.repeat(img, 3, axis=-1)\n",
        "\n",
        "        img_pil = Image.fromarray(img).resize(target_size)\n",
        "\n",
        "        # === Calcular mÃ©tricas SSIM y PSNR ===\n",
        "        x_fake = transform(img_pil).numpy()\n",
        "        ssim_val = skimage.metrics.structural_similarity(\n",
        "            x_real.transpose(1, 2, 0),\n",
        "            x_fake.transpose(1, 2, 0),\n",
        "            channel_axis=-1,\n",
        "            data_range=1.0\n",
        "        )\n",
        "        psnr_val = skimage.metrics.peak_signal_noise_ratio(\n",
        "            x_real, x_fake, data_range=1.0\n",
        "        )\n",
        "\n",
        "        # === LPIPS ===\n",
        "        x_real_torch = torch.tensor(x_real).unsqueeze(0).to(device)\n",
        "        x_fake_torch = torch.tensor(x_fake).unsqueeze(0).to(device)\n",
        "        lpips_val = loss_fn_lpips(x_real_torch, x_fake_torch).item()\n",
        "\n",
        "        # === JSD ===\n",
        "        jsd_val = compute_jsd(x_real, x_fake)\n",
        "\n",
        "        # === FID (si existe en metric-fid50k_full.jsonl) ===\n",
        "        fid_val = fid_dict.get(snap_name, None)\n",
        "\n",
        "        # === KID ===\n",
        "        # Normalizar imÃ¡genes a [0,1] y tensor 3xHxW\n",
        "        x_real_torch_incep = x_real_torch.clone()\n",
        "        x_fake_torch_incep = x_fake_torch.clone()\n",
        "        kid_val = compute_kid(\n",
        "            [x_real_torch.cpu()],\n",
        "            [x_fake_torch.cpu()]\n",
        "        )\n",
        "\n",
        "        # === PPL ===\n",
        "        ppl_val = compute_ppl(G, device, n_samples=64, eps=1e-4)\n",
        "\n",
        "        # === Guardar fila ===\n",
        "        all_rows.append([\n",
        "          epoch, g_loss, d_loss, fid_val, kid_val, ssim_val, psnr_val,\n",
        "          lpips_val, jsd_val, ppl_val, kimg_snap, run_id\n",
        "      ])\n",
        "\n",
        "    # ---- Actualizar offset con el Ãºltimo snapshot de esta carpeta ----\n",
        "    if snapshot_paths:\n",
        "        last_local = max(int(re.search(r'network-snapshot-(\\d+).pkl', s).group(1)) for s in snapshot_paths)\n",
        "        kimg_offset += last_local  # se suma al offset global\n",
        "\n",
        "# ================== GUARDAR CSV ==================\n",
        "df_all = pd.DataFrame(all_rows, columns=[\n",
        "    'epoch', 'G_loss', 'D_loss', 'FID', 'KID', 'SSIM', 'PSNR',\n",
        "    'LPIPS', 'JSD', 'PPL', 'kimg', 'run_id'\n",
        "])\n",
        "df_all = df_all.sort_values(['kimg'])\n",
        "df_all.to_csv(out_csv, index=False)\n",
        "print(f\"CSV final con snapshots guardado en: {out_csv}\")\n"
      ],
      "metadata": {
        "id": "Wik06kl7PVNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# NÃºmero de imÃ¡genes en tu dataset\n",
        "N_images = 40120   # cÃ¡mbialo si tu dataset cambia\n",
        "mirror = 0         # ponlo en 1 si usaste --mirror=1\n",
        "N_eff = N_images * (2 if mirror == 1 else 1)\n",
        "\n",
        "# Ruta donde estÃ¡n los resultados\n",
        "results_dir = \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/resultsE2\"\n",
        "progreso_dir = \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/progresoE2\"\n",
        "os.makedirs(progreso_dir, exist_ok=True)\n",
        "\n",
        "# Inicializar lista de DataFrames\n",
        "all_runs_data = []\n",
        "\n",
        "# Buscar todas las carpetas de runs\n",
        "run_dirs = sorted(glob.glob(f'{results_dir}/0000*'))\n",
        "\n",
        "# Offset acumulado de kimg\n",
        "kimg_offset = 0\n",
        "\n",
        "for run_dir in run_dirs:\n",
        "    run_id = os.path.basename(run_dir)\n",
        "\n",
        "    stats_path = os.path.join(run_dir, 'stats.jsonl')\n",
        "    if not os.path.exists(stats_path):\n",
        "        print(f\"Stats no encontrado para {run_id}, se omite.\")\n",
        "        continue\n",
        "\n",
        "    # Leer cada lÃ­nea JSON\n",
        "    with open(stats_path, 'r') as f:\n",
        "        lines = [json.loads(line) for line in f]\n",
        "\n",
        "    rows = []\n",
        "    for entry in lines:\n",
        "        try:\n",
        "            kimg = entry['Progress/kimg']['mean'] if isinstance(entry['Progress/kimg'], dict) else entry['Progress/kimg']\n",
        "            g_loss = entry['Loss/G/loss']['mean'] if isinstance(entry['Loss/G/loss'], dict) else entry['Loss/G/loss']\n",
        "            d_loss = entry['Loss/D/loss']['mean'] if isinstance(entry['Loss/D/loss'], dict) else entry['Loss/D/loss']\n",
        "\n",
        "            # Calcular kimg acumulado\n",
        "            kimg_total = kimg + kimg_offset\n",
        "\n",
        "            # Convertir a Ã©pocas\n",
        "            epoch = (kimg_total * 1000) / N_eff\n",
        "\n",
        "            # Guardar fila\n",
        "            rows.append({\n",
        "                'epoch': epoch,         # columna 1: Ã©pocas acumuladas\n",
        "                'G_loss': g_loss,       # columna 2\n",
        "                'D_loss': d_loss,       # columna 3\n",
        "                'kimg': kimg_total,     # columna 4: kimg acumulado\n",
        "                'run_id': run_id        # columna 5: carpeta origen\n",
        "            })\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "    # Si se recogieron datos en este run\n",
        "    if rows:\n",
        "        df_run = pd.DataFrame(rows)\n",
        "        all_runs_data.append(df_run)\n",
        "\n",
        "        # Actualizar offset: sumar el Ãºltimo kimg de esta carpeta\n",
        "        last_kimg = df_run['kimg'].max() - kimg_offset  # solo lo local\n",
        "        kimg_offset += last_kimg\n",
        "\n",
        "# Combinar todos los runs en un solo DataFrame\n",
        "df_all = pd.concat(all_runs_data, ignore_index=True)\n",
        "\n",
        "# Guardar como CSV\n",
        "out_csv = os.path.join(progreso_dir, 'losses_all_runs.csv')\n",
        "df_all.to_csv(out_csv, index=False)\n",
        "print(f\"CSV combinado guardado en: {out_csv}\")\n"
      ],
      "metadata": {
        "id": "kl64GUxGPXv3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}