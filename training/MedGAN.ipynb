{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard\n",
        "import os, sys, json, glob, re, math, random, pickle, time, datetime, subprocess, logging, argparse\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "from pathlib import Path\n",
        "\n",
        "# Scientific\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import linalg\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as vutils\n",
        "from torch import Tensor\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.models import inception_v3, Inception_V3_Weights\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "from torchmetrics.image.kid import KernelInceptionDistance\n",
        "\n",
        "# === Librer√≠as para m√©tricas ===\n",
        "import lpips\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "\n",
        "\n",
        "from src.medgan.dataset import dstget\n",
        "from src.medgan.dcgan import DCGAN_G, DCGAN_D\n",
        "from src.medgan.mlp import MLP_G, MLP_D\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXHItI9BgokE"
      },
      "outputs": [],
      "source": [
        "PROJECT_ROOT = Path.cwd().parent\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"medgan\"\n",
        "EXPERIMENTS_DIR = PROJECT_ROOT / \"experiments\" / \"medgan\"\n",
        "RESULTS_DIR = PROJECT_ROOT / \"results\" / \"medgan\"\n",
        "\n",
        "CHECKPOINT_ROOT = EXPERIMENTS_DIR / \"checkpoints\"\n",
        "GENERATED_ROOT = RESULTS_DIR / \"generated\"\n",
        "METRICS_ROOT = RESULTS_DIR / \"metrics\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et8khyFu7x01"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMXP1ohe71Rk"
      },
      "outputs": [],
      "source": [
        "#toolsf.py\n",
        "def sg_fk_img_gnrt(model, noise, dir, begin_idx=0):\n",
        "    \"\"\"Genera im√°genes falsas individuales y las guarda en un directorio.\"\"\"\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake = model(noise)\n",
        "    fake = fake.mul(0.5).add(0.5)  # de [-1,1] a [0,1]\n",
        "\n",
        "    image_num = fake.shape[0]\n",
        "    for i in range(image_num):\n",
        "        image_path = os.path.join(dir, '{}.png'.format(begin_idx + i + 1))\n",
        "        vutils.save_image(fake[i, :, :, :], image_path, normalize=True)\n",
        "\n",
        "def bc_rl_img_gnrt(real_data, dir, iter):\n",
        "    \"\"\"Guarda un batch de im√°genes reales.\"\"\"\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "    real_cpu = real_data.mul(0.5).add(0.5)\n",
        "    image_path = os.path.join(dir, '{}_real_samples.png'.format(iter))\n",
        "    vutils.save_image(real_cpu, image_path, normalize=True)\n",
        "\n",
        "def bc_fk_img_gnrt(model, noise, dir, iter):\n",
        "    \"\"\"Genera un batch de im√°genes falsas y las guarda.\"\"\"\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake = model(noise)\n",
        "    fake = fake.mul(0.5).add(0.5)\n",
        "    fake_image_path = os.path.join(dir, '{}_fake_samples.png'.format(iter))\n",
        "    vutils.save_image(fake, fake_image_path, normalize=True)\n",
        "\n",
        "def timage_gnrt(model, real_data, noise, root, iter):\n",
        "    \"\"\"Genera un set de im√°genes reales y falsas en un mismo paso.\"\"\"\n",
        "    sg_fk_dir = os.path.join(root, 'sg_fk_img', str(iter))\n",
        "    sg_fk_img_gnrt(model, noise, sg_fk_dir)\n",
        "\n",
        "    bc_rl_dir = os.path.join(root, 'bc_img')\n",
        "    bc_rl_img_gnrt(real_data, bc_rl_dir, iter)\n",
        "\n",
        "    bc_fk_dir = os.path.join(root, 'bc_img')\n",
        "    bc_fk_img_gnrt(model, noise, bc_fk_dir, iter)\n",
        "\n",
        "def model_save(netG, netD, iter, dir):\n",
        "    \"\"\"Guarda el estado de generador y discriminador.\"\"\"\n",
        "    model_save_dir = os.path.join(dir, 'save_model')\n",
        "    if not os.path.exists(model_save_dir):\n",
        "        os.makedirs(model_save_dir)\n",
        "\n",
        "    G_save_path = os.path.join(model_save_dir, 'netG_iter{}.pth'.format(iter))\n",
        "    D_save_path = os.path.join(model_save_dir, 'netD_iter{}.pth'.format(iter))\n",
        "    torch.save(netG.state_dict(), G_save_path)\n",
        "    torch.save(netD.state_dict(), D_save_path)\n",
        "\n",
        "def isok(sub_list):\n",
        "    for item in sub_list:\n",
        "        if item.poll() is None:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def execute_command(cmdstring_list, cwd=None, timeout=None, shell=True):\n",
        "    \"\"\"Ejecuta comandos de shell de forma secuencial.\"\"\"\n",
        "    if timeout:\n",
        "        end_time = datetime.datetime.now() + datetime.timedelta(seconds=timeout)\n",
        "\n",
        "    sub_list = []\n",
        "    for i, item in enumerate(cmdstring_list):\n",
        "        sub = subprocess.Popen(item, cwd=cwd, stdin=subprocess.PIPE,\n",
        "                               shell=shell, bufsize=4096)\n",
        "        time.sleep(1.1)\n",
        "        sub_list.append(sub)\n",
        "\n",
        "    print('Comenzando ejecuci√≥n...')\n",
        "    while True:\n",
        "        if isok(sub_list) is True:\n",
        "            break\n",
        "        time.sleep(0.5)\n",
        "    print('Ejecuci√≥n finalizada.')\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Calcula y almacena el promedio y el valor actual.\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Calcula accuracy en top-k.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "def get_logger(file_path):\n",
        "    logger = logging.getLogger('ecogan')\n",
        "    log_format = '%(asctime)s | %(message)s'\n",
        "    formatter = logging.Formatter(log_format, datefmt='%m/%d %I:%M:%S %p')\n",
        "    file_handler = logging.FileHandler(file_path)\n",
        "    file_handler.setFormatter(formatter)\n",
        "    stream_handler = logging.StreamHandler()\n",
        "    stream_handler.setFormatter(formatter)\n",
        "\n",
        "    logger.addHandler(file_handler)\n",
        "    logger.addHandler(stream_handler)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    return logger\n",
        "\n",
        "def lgwt_construct(logpath):\n",
        "    \"\"\"Construye un logger simple.\"\"\"\n",
        "    logger = get_logger(logpath)\n",
        "    return logger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggpYlaSK_ktK"
      },
      "source": [
        "## Modelos de Evaluacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JLwTHW-_j86"
      },
      "outputs": [],
      "source": [
        "# resnet.py\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152']\n",
        "\n",
        "\n",
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1,\n",
        "            groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# BasicBlock y Bottleneck (sin cambios)\n",
        "###############################################################################\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        "    def __init__(self, inplanes: int, planes: int, stride: int = 1,\n",
        "                 downsample: Optional[nn.Module] = None, groups: int = 1,\n",
        "                 base_width: int = 64, dilation: int = 1,\n",
        "                 norm_layer: Optional[Callable[..., nn.Module]] = None) -> None:\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion: int = 4\n",
        "    def __init__(self, inplanes: int, planes: int, stride: int = 1,\n",
        "                 downsample: Optional[nn.Module] = None, groups: int = 1,\n",
        "                 base_width: int = 64, dilation: int = 1,\n",
        "                 norm_layer: Optional[Callable[..., nn.Module]] = None) -> None:\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# ResNet adaptado para escala de grises y GAN Discriminator\n",
        "###############################################################################\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block: Type[Union[BasicBlock, Bottleneck]],\n",
        "                 layers: List[int],\n",
        "                 num_classes: int = 1,  # GAN discriminator: real/fake\n",
        "                 zero_init_residual: bool = False,\n",
        "                 groups: int = 1,\n",
        "                 width_per_group: int = 64,\n",
        "                 replace_stride_with_dilation: Optional[List[bool]] = None,\n",
        "                 norm_layer: Optional[Callable[..., nn.Module]] = None) -> None:\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None or a 3-element tuple\")\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        # Cambiado a 1 canal en vez de 3\n",
        "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # salida: 1 score (real/fake)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes,\n",
        "                                groups=self.groups, base_width=self.base_width,\n",
        "                                dilation=self.dilation, norm_layer=norm_layer))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x  # (batch, 1)\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# Helpers: versiones de ResNet para GAN\n",
        "###############################################################################\n",
        "def resnet18(**kwargs: Any) -> ResNet:\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "\n",
        "def resnet34(**kwargs: Any) -> ResNet:\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "\n",
        "def resnet50(**kwargs: Any) -> ResNet:\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JfbDSnuzmTo"
      },
      "source": [
        "## ADA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BfVNXrIXtIK",
        "outputId": "d8d37b2b-5a18-4bdd-de29-12c11a4e1617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ √öltimo checkpoint encontrado: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00000_checkpoint\n",
            "üîÑ √öltimo checkpoint coincidente: epoch 70\n",
            "   - netG: netG_epoch70.pth\n",
            "   - netD: netD_epoch70.pth\n"
          ]
        }
      ],
      "source": [
        "# Ruta base de checkpoints\n",
        "checkpoint_base = \"/content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1\"\n",
        "\n",
        "# Buscar √∫ltima carpeta\n",
        "checkpoint_dirs = sorted(glob.glob(os.path.join(checkpoint_base, \"*_checkpoint\")))\n",
        "if not checkpoint_dirs:\n",
        "    print(\"‚ö†Ô∏è No se encontr√≥ ning√∫n checkpoint. El entrenamiento empezar√° desde cero.\")\n",
        "    last_epoch = 0\n",
        "    last_checkpoint_dir = None\n",
        "else:\n",
        "    last_checkpoint_dir = checkpoint_dirs[-1]\n",
        "    print(f\"‚úÖ √öltimo checkpoint encontrado: {last_checkpoint_dir}\")\n",
        "\n",
        "    # Buscar archivos de netG y netD\n",
        "    netG_files = glob.glob(os.path.join(last_checkpoint_dir, \"netG_epoch*.pth\"))\n",
        "    netD_files = glob.glob(os.path.join(last_checkpoint_dir, \"netD_epoch*.pth\"))\n",
        "\n",
        "    # Extraer n√∫meros de √©poca\n",
        "    def extract_epochs(files, prefix):\n",
        "        epochs = []\n",
        "        for f in files:\n",
        "            m = re.search(rf\"{prefix}_epoch(\\d+)\\.pth\", os.path.basename(f))\n",
        "            if m:\n",
        "                epochs.append(int(m.group(1)))\n",
        "        return sorted(epochs)\n",
        "\n",
        "    G_epochs = extract_epochs(netG_files, \"netG\")\n",
        "    D_epochs = extract_epochs(netD_files, \"netD\")\n",
        "\n",
        "    if not G_epochs or not D_epochs:\n",
        "        print(\"‚ö†Ô∏è No se encontraron checkpoints completos de G y D.\")\n",
        "        last_epoch = 0\n",
        "    else:\n",
        "        # Buscar la √∫ltima √©poca que est√© en ambos\n",
        "        common_epochs = sorted(set(G_epochs).intersection(D_epochs))\n",
        "        if not common_epochs:\n",
        "            print(\"‚ö†Ô∏è No hay √©pocas coincidentes entre G y D.\")\n",
        "            last_epoch = 0\n",
        "        else:\n",
        "            last_epoch = common_epochs[-1]\n",
        "            print(f\"üîÑ √öltimo checkpoint coincidente: epoch {last_epoch}\")\n",
        "            print(f\"   - netG: netG_epoch{last_epoch}.pth\")\n",
        "            print(f\"   - netD: netD_epoch{last_epoch}.pth\")\n",
        "\n",
        "# Ahora `last_checkpoint_dir` y `last_epoch` te sirven para cargar en el training loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppwhz7joA_Oz",
        "outputId": "09dbc627-5dff-4e50-85df-55b753ec07c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.12/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "üé≤ Random Seed: 7582\n",
            "‚úÖ Carpeta de checkpoints encontrada: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00000_checkpoint\n",
            "üîÑ Reanudando desde checkpoint epoch 70 en /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00000_checkpoint\n",
            "üìÇ Nueva carpeta de checkpoints creada: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 71/2000] Loss_D: -1.0943 | Loss_G: 1.1747\n",
            "[√âpoca 72/2000] Loss_D: -0.8682 | Loss_G: 1.2210\n",
            "[√âpoca 73/2000] Loss_D: -0.8029 | Loss_G: 0.8111\n",
            "[√âpoca 74/2000] Loss_D: -0.3731 | Loss_G: 0.7124\n",
            "[√âpoca 75/2000] Loss_D: -0.6022 | Loss_G: 1.1260\n",
            "üóÇÔ∏è Calculando features reales y guardando en: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint/inception_feats_real.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4222778774.py:190: DeprecationWarning: The `disp` argument is deprecated and will be removed in SciPy 1.18.0.\n",
            "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 75 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 76/2000] Loss_D: -1.1357 | Loss_G: 1.0560\n",
            "[√âpoca 77/2000] Loss_D: -0.8697 | Loss_G: 0.8433\n",
            "[√âpoca 78/2000] Loss_D: -0.4001 | Loss_G: 0.3830\n",
            "[√âpoca 79/2000] Loss_D: -0.9265 | Loss_G: 0.6249\n",
            "[√âpoca 80/2000] Loss_D: -0.9373 | Loss_G: 1.1962\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 80 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 81/2000] Loss_D: -0.7548 | Loss_G: 0.6167\n",
            "[√âpoca 82/2000] Loss_D: -0.4359 | Loss_G: 0.3954\n",
            "[√âpoca 83/2000] Loss_D: -0.7421 | Loss_G: 1.1746\n",
            "[√âpoca 84/2000] Loss_D: -0.8215 | Loss_G: 1.0196\n",
            "[√âpoca 85/2000] Loss_D: -0.4871 | Loss_G: 0.5437\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 85 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 86/2000] Loss_D: -0.5356 | Loss_G: 0.7442\n",
            "[√âpoca 87/2000] Loss_D: -0.9856 | Loss_G: 0.4035\n",
            "[√âpoca 88/2000] Loss_D: -0.8843 | Loss_G: 0.7426\n",
            "[√âpoca 89/2000] Loss_D: -0.1968 | Loss_G: 0.7092\n",
            "[√âpoca 90/2000] Loss_D: -1.1770 | Loss_G: 1.2726\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 90 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 91/2000] Loss_D: -0.2464 | Loss_G: 0.7239\n",
            "[√âpoca 92/2000] Loss_D: -0.3303 | Loss_G: 0.8684\n",
            "[√âpoca 93/2000] Loss_D: -0.6983 | Loss_G: 0.4890\n",
            "[√âpoca 94/2000] Loss_D: -0.8330 | Loss_G: 0.8514\n",
            "[√âpoca 95/2000] Loss_D: -0.4509 | Loss_G: 0.9918\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 95 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 96/2000] Loss_D: -0.9166 | Loss_G: 1.0546\n",
            "[√âpoca 97/2000] Loss_D: -0.6754 | Loss_G: 0.7989\n",
            "[√âpoca 98/2000] Loss_D: -0.3660 | Loss_G: 0.3735\n",
            "[√âpoca 99/2000] Loss_D: -0.8840 | Loss_G: 1.2615\n",
            "[√âpoca 100/2000] Loss_D: -0.9888 | Loss_G: 0.9232\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 100 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 101/2000] Loss_D: -0.2660 | Loss_G: 1.1291\n",
            "[√âpoca 102/2000] Loss_D: -0.4426 | Loss_G: 0.9854\n",
            "[√âpoca 103/2000] Loss_D: -1.1270 | Loss_G: 1.2057\n",
            "[√âpoca 104/2000] Loss_D: -0.4604 | Loss_G: 1.2558\n",
            "[√âpoca 105/2000] Loss_D: -0.4312 | Loss_G: 0.7996\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 105 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 106/2000] Loss_D: -0.3808 | Loss_G: 0.6565\n",
            "[√âpoca 107/2000] Loss_D: -0.5031 | Loss_G: 0.3583\n",
            "[√âpoca 108/2000] Loss_D: -0.4913 | Loss_G: 0.2127\n",
            "[√âpoca 109/2000] Loss_D: -0.7183 | Loss_G: 1.2242\n",
            "[√âpoca 110/2000] Loss_D: -0.6208 | Loss_G: 0.9832\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 110 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 111/2000] Loss_D: -0.6165 | Loss_G: 0.8120\n",
            "[√âpoca 112/2000] Loss_D: -0.4483 | Loss_G: 0.6664\n",
            "[√âpoca 113/2000] Loss_D: -0.6777 | Loss_G: 0.9631\n",
            "[√âpoca 114/2000] Loss_D: -0.3087 | Loss_G: 0.6482\n",
            "[√âpoca 115/2000] Loss_D: -1.0166 | Loss_G: 1.2104\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 115 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 116/2000] Loss_D: -0.2909 | Loss_G: 1.0004\n",
            "[√âpoca 117/2000] Loss_D: -0.4719 | Loss_G: 0.4252\n",
            "[√âpoca 118/2000] Loss_D: -0.1340 | Loss_G: 0.7939\n",
            "[√âpoca 119/2000] Loss_D: -0.6614 | Loss_G: 0.5219\n",
            "[√âpoca 120/2000] Loss_D: -0.8748 | Loss_G: 1.1466\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 120 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 121/2000] Loss_D: -0.4135 | Loss_G: 0.6430\n",
            "[√âpoca 122/2000] Loss_D: -0.5976 | Loss_G: 0.6629\n",
            "[√âpoca 123/2000] Loss_D: -0.7346 | Loss_G: 0.9815\n",
            "[√âpoca 124/2000] Loss_D: -1.2258 | Loss_G: 1.1711\n",
            "[√âpoca 125/2000] Loss_D: -0.7810 | Loss_G: 0.6382\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 125 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 126/2000] Loss_D: -0.7354 | Loss_G: 0.9481\n",
            "[√âpoca 127/2000] Loss_D: -0.4551 | Loss_G: 0.6004\n",
            "[√âpoca 128/2000] Loss_D: -0.9123 | Loss_G: 0.7734\n",
            "[√âpoca 129/2000] Loss_D: -0.2223 | Loss_G: 0.6894\n",
            "[√âpoca 130/2000] Loss_D: -0.4200 | Loss_G: 0.7516\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 130 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 131/2000] Loss_D: -0.1710 | Loss_G: 0.7623\n",
            "[√âpoca 132/2000] Loss_D: -0.6174 | Loss_G: 0.9288\n",
            "[√âpoca 133/2000] Loss_D: -0.6552 | Loss_G: 0.5642\n",
            "[√âpoca 134/2000] Loss_D: -0.2532 | Loss_G: 0.5401\n",
            "[√âpoca 135/2000] Loss_D: -0.3515 | Loss_G: 0.6682\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 135 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 136/2000] Loss_D: -0.9085 | Loss_G: 1.1365\n",
            "[√âpoca 137/2000] Loss_D: -0.6713 | Loss_G: 0.6605\n",
            "[√âpoca 138/2000] Loss_D: -0.3947 | Loss_G: 0.6210\n",
            "[√âpoca 139/2000] Loss_D: -0.3969 | Loss_G: 0.7308\n",
            "[√âpoca 140/2000] Loss_D: -0.4388 | Loss_G: 0.6707\n",
            "‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca 140 ‚Äî Carpeta: /content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA/CheckpointsE1/00001_checkpoint\n",
            "[√âpoca 141/2000] Loss_D: -1.0040 | Loss_G: 1.2626\n",
            "[√âpoca 142/2000] Loss_D: -0.6867 | Loss_G: 0.3947\n",
            "[√âpoca 143/2000] Loss_D: -1.1642 | Loss_G: 1.1329\n"
          ]
        }
      ],
      "source": [
        "# Continuaci√≥n con manejo de checkpoints y logging mejorado)\n",
        "one = torch.FloatTensor([1]).to(device)\n",
        "mone = (one * -1).to(device)\n",
        "\n",
        "# LPIPS (usa inputs en rango [-1,1], 3 canales)\n",
        "lpips_fn = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "\n",
        "def argsget():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--dataset', default=\"other\")\n",
        "    parser.add_argument('--dataroot', default=\"/content/drive/MyDrive/Proyecto_Grado/Data/frames_extraidos_MedGAN\")\n",
        "    parser.add_argument('--workers', type=int, default=4)\n",
        "    parser.add_argument('--batchSize', type=int, default=20)\n",
        "    parser.add_argument('--img_size', type=int, default=128)\n",
        "    parser.add_argument('--nc', type=int, default=1)\n",
        "    parser.add_argument('--nz', type=int, default=100)\n",
        "    parser.add_argument('--ngf', type=int, default=64)\n",
        "    parser.add_argument('--ndf', type=int, default=64)\n",
        "    parser.add_argument('--niter', type=int, default=2000)\n",
        "    parser.add_argument('--lrD', type=float, default=0.00005)\n",
        "    parser.add_argument('--lrG', type=float, default=0.00005)\n",
        "    parser.add_argument('--beta1', type=float, default=0.5)\n",
        "    parser.add_argument('--ngpu', type=int, default=1)\n",
        "    parser.add_argument('--netG', default='')\n",
        "    parser.add_argument('--netD', default='')\n",
        "    parser.add_argument('--clamp_lower', type=float, default=-0.01)\n",
        "    parser.add_argument('--clamp_upper', type=float, default=0.01)\n",
        "    parser.add_argument('--Diters', type=int, default=5)\n",
        "    parser.add_argument('--noBN', action='store_true')\n",
        "    parser.add_argument('--mlp_G', action='store_true')\n",
        "    parser.add_argument('--mlp_D', action='store_true')\n",
        "    parser.add_argument('--n_extra_layers', type=int, default=0)\n",
        "    parser.add_argument('--experiment', default='/content/drive/MyDrive/Proyecto_Grado/MedGAN/ADA')\n",
        "    parser.add_argument('--adam', action='store_true')\n",
        "    parser.add_argument('--class_name', type=str, default='ecocardio')\n",
        "    parser.add_argument('--T1', type=float, default=0.3)\n",
        "    parser.add_argument('--T2', type=float, default=0.5)\n",
        "    opt = parser.parse_args(args=[])\n",
        "    return opt\n",
        "\n",
        "\n",
        "def mkdir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "def discriminator_train(netD, netG, data, noise, optimizerD, opt):\n",
        "    for p in netD.parameters():\n",
        "        p.requires_grad = True\n",
        "        p.data.clamp_(opt.clamp_lower, opt.clamp_upper)\n",
        "\n",
        "    netD.zero_grad()\n",
        "\n",
        "    real = data.to(device)\n",
        "    errD_real = netD(real)\n",
        "    errD_real.backward(one)\n",
        "\n",
        "    noise.resize_(opt.batchSize, opt.nz, 1, 1).normal_(0, 1)\n",
        "    fake = netG(noise).detach()\n",
        "    errD_fake = netD(fake)\n",
        "    errD_fake.backward(mone)\n",
        "\n",
        "    errD = errD_real - errD_fake\n",
        "    optimizerD.step()\n",
        "    return errD_real, errD_fake, errD\n",
        "\n",
        "\n",
        "def discriminator_infer(netD, netG, data, noise, opt):\n",
        "    with torch.no_grad():\n",
        "        real = data.to(device)\n",
        "        c_errD_real = netD(real)\n",
        "\n",
        "        noise.resize_(opt.batchSize, opt.nz, 1, 1).normal_(0, 1)\n",
        "        fake = netG(noise)\n",
        "        c_errD_fake = netD(fake)\n",
        "        c_errD = c_errD_real - c_errD_fake\n",
        "\n",
        "    return c_errD_real, c_errD_fake, c_errD\n",
        "\n",
        "\n",
        "def generator_train(netG, netD, noise, optimizerG, opt):\n",
        "    netG.zero_grad()\n",
        "    noise.resize_(opt.batchSize, opt.nz, 1, 1).normal_(0, 1)\n",
        "    fake = netG(noise)\n",
        "    errG = netD(fake)\n",
        "    errG.backward(one)\n",
        "    optimizerG.step()\n",
        "    return errG\n",
        "\n",
        "\n",
        "# === Funciones de m√©tricas ===\n",
        "class InceptionV3_FID(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        inception = inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1, transform_input=False)\n",
        "        inception.fc = nn.Identity()   # quitamos la clasificaci√≥n\n",
        "        inception.eval()\n",
        "        for p in inception.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # Nos quedamos solo con las capas hasta el pen√∫ltimo bloque (pool3 ‚Üí 2048D)\n",
        "        self.features = nn.Sequential(\n",
        "            inception.Conv2d_1a_3x3,\n",
        "            inception.Conv2d_2a_3x3,\n",
        "            inception.Conv2d_2b_3x3,\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            inception.Conv2d_3b_1x1,\n",
        "            inception.Conv2d_4a_3x3,\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            inception.Mixed_5b,\n",
        "            inception.Mixed_5c,\n",
        "            inception.Mixed_5d,\n",
        "            inception.Mixed_6a,\n",
        "            inception.Mixed_6b,\n",
        "            inception.Mixed_6c,\n",
        "            inception.Mixed_6d,\n",
        "            inception.Mixed_6e,\n",
        "            inception.Mixed_7a,\n",
        "            inception.Mixed_7b,\n",
        "            inception.Mixed_7c,\n",
        "            inception.avgpool,   # AdaptiveAvgPool2d ‚Üí [N,2048,1,1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Resize a 299x299 (requisito InceptionV3)\n",
        "        x = F.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "        if x.shape[1] == 1:  # grayscale ‚Üí RGB\n",
        "            x = x.repeat(1, 3, 1, 1)\n",
        "        with torch.no_grad():\n",
        "            feats = self.features(x)       # [N, 2048, 1, 1]\n",
        "            feats = torch.flatten(feats, 1)  # [N, 2048]\n",
        "        return feats\n",
        "\n",
        "# === C√°lculo del FID ===\n",
        "fid_inception = InceptionV3_FID().to(device)\n",
        "\n",
        "def calculate_fid(real, fake):\n",
        "    real = (real + 1) / 2  # [-1,1] ‚Üí [0,1]\n",
        "    fake = (fake + 1) / 2\n",
        "    with torch.no_grad():\n",
        "        act_real = fid_inception(real.to(device)).cpu().numpy()\n",
        "        act_fake = fid_inception(fake.to(device)).cpu().numpy()\n",
        "\n",
        "    mu_real, sigma_real = np.mean(act_real, axis=0), np.cov(act_real, rowvar=False)\n",
        "    mu_fake, sigma_fake = np.mean(act_fake, axis=0), np.cov(act_fake, rowvar=False)\n",
        "\n",
        "    diff = mu_real - mu_fake\n",
        "    covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "\n",
        "    fid = diff.dot(diff) + np.trace(sigma_real + sigma_fake - 2 * covmean)\n",
        "    return float(fid)\n",
        "\n",
        "\n",
        "# === Funciones de m√©tricas ===\n",
        "def calculate_metrics(real, fake):\n",
        "    real_dev = real.detach().to(device)\n",
        "    fake_dev = fake.detach().to(device)\n",
        "\n",
        "    # LPIPS (usa RGB)\n",
        "    if real_dev.shape[1] == 1:\n",
        "        real_3 = real_dev.repeat(1, 3, 1, 1)\n",
        "        fake_3 = fake_dev.repeat(1, 3, 1, 1)\n",
        "    else:\n",
        "        real_3, fake_3 = real_dev, fake_dev\n",
        "\n",
        "    with torch.no_grad():\n",
        "        lpips_score = lpips_fn(real_3, fake_3).mean().item()\n",
        "\n",
        "    # === FID estilo StyleGAN2-ADA ===\n",
        "    fid_val = calculate_fid(real_dev, fake_dev)\n",
        "\n",
        "    # SSIM y PSNR (en numpy, escala 0-255)\n",
        "    real_np = (real_dev.detach().cpu().numpy().transpose(0, 2, 3, 1) * 127.5 + 127.5).astype(np.uint8)\n",
        "    fake_np = (fake_dev.detach().cpu().numpy().transpose(0, 2, 3, 1) * 127.5 + 127.5).astype(np.uint8)\n",
        "\n",
        "    ssim_vals, psnr_vals = [], []\n",
        "    for i in range(min(len(real_np), len(fake_np))):\n",
        "        r = real_np[i].squeeze()\n",
        "        f = fake_np[i].squeeze()\n",
        "        ssim_vals.append(ssim(r, f, data_range=255))\n",
        "        psnr_vals.append(psnr(r, f, data_range=255))\n",
        "\n",
        "    ssim_mean = float(np.mean(ssim_vals)) if ssim_vals else 0.0\n",
        "    psnr_mean = float(np.mean(psnr_vals)) if psnr_vals else 0.0\n",
        "\n",
        "    try:\n",
        "        jsd_val = float(jensenshannon(real_np.flatten(), fake_np.flatten()))\n",
        "    except Exception:\n",
        "        jsd_val = None\n",
        "\n",
        "    return {\n",
        "        \"FID\": fid_val,\n",
        "        \"SSIM\": ssim_mean,\n",
        "        \"PSNR\": psnr_mean,\n",
        "        \"LPIPS\": lpips_score,\n",
        "        \"JSD\": jsd_val\n",
        "    }\n",
        "\n",
        "def compute_kid(feat_real, feat_fake, num_subsets=100, max_subset_size=1000):\n",
        "    \"\"\"MMD-based KID with polynomial(3) kernel ‚Äî igual que la implementaci√≥n de NVIDIA.\"\"\"\n",
        "    n = feat_real.shape[1]\n",
        "    m = min(min(feat_real.shape[0], feat_fake.shape[0]), max_subset_size)\n",
        "    t = 0.0\n",
        "    for _ in range(num_subsets):\n",
        "        x = feat_fake[np.random.choice(feat_fake.shape[0], m, replace=False)]\n",
        "        y = feat_real[np.random.choice(feat_real.shape[0], m, replace=False)]\n",
        "        a = (x @ x.T / n + 1) ** 3 + (y @ y.T / n + 1) ** 3\n",
        "        b = (x @ y.T / n + 1) ** 3\n",
        "        # (a.sum() - diag(a).sum())/(m-1) - 2 * b.sum() / m\n",
        "        t += (a.sum() - np.diag(a).sum()) / (m - 1) - 2.0 * b.sum() / m\n",
        "    return float(t / num_subsets / m)\n",
        "\n",
        "def _images_to_uint8(images):\n",
        "    \"\"\"Convierte un batch tensor [-1,1] o [0,1] a uint8 [0,255], formato NCHW -> N H W C numpy uint8.\"\"\"\n",
        "    # aceptamos im√°genes en [-1,1] (t√≠pico) o [0,1]\n",
        "    imgs = images.detach().cpu()\n",
        "    if imgs.min() < 0.0:  # asumimos [-1,1]\n",
        "        imgs = (imgs + 1.0) * 127.5 + 0.0\n",
        "    else:\n",
        "        imgs = imgs * 255.0\n",
        "    imgs = imgs.clamp(0, 255).numpy().transpose(0, 2, 3, 1).astype(np.uint8)\n",
        "    return imgs\n",
        "\n",
        "def compute_and_cache_real_feats(dataloader, cache_file, max_reals=None):\n",
        "    \"\"\"Extrae features Inception (2048D) para todo el dataset real y los cachea en cache_file (pickle).\"\"\"\n",
        "    if os.path.isfile(cache_file):\n",
        "        with open(cache_file, \"rb\") as f:\n",
        "            feat_real = pickle.load(f)\n",
        "        return feat_real\n",
        "\n",
        "    feat_real = []\n",
        "    print(f\"üóÇÔ∏è Calculando features reales y guardando en: {cache_file}\")\n",
        "    for imgs, _ in dataloader:\n",
        "        # imgs: tensor NCHW, en tu pipeline parecen estar en [-1,1]\n",
        "        imgs_uint8 = _images_to_uint8(imgs)  # numpy uint8 HWC\n",
        "        # convert back to tensor normalized to [0,1] for fid_inception usage\n",
        "        imgs_t = torch.from_numpy(imgs_uint8.astype(np.float32) / 255.0).permute(0,3,1,2)\n",
        "        # fid_inception espera floats en [0,1] y har√° resize\n",
        "        with torch.no_grad():\n",
        "            feats = fid_inception(imgs_t.to(device)).cpu().numpy()  # (N,2048)\n",
        "        feat_real.append(feats)\n",
        "        if max_reals is not None and sum([f.shape[0] for f in feat_real]) >= max_reals:\n",
        "            break\n",
        "    feat_real = np.vstack(feat_real)\n",
        "    if max_reals is not None and feat_real.shape[0] > max_reals:\n",
        "        feat_real = feat_real[:max_reals]\n",
        "    # cache\n",
        "    with open(cache_file, \"wb\") as f:\n",
        "        pickle.dump(feat_real, f)\n",
        "    return feat_real\n",
        "\n",
        "def compute_fake_feats_from_generator(netG, num_fakes, batch_size, nz, device):\n",
        "    \"\"\"Genera num_fakes im√°genes con netG y extrae sus features Inception (2048D).\"\"\"\n",
        "    feat_fake = []\n",
        "    netG.eval()\n",
        "    with torch.no_grad():\n",
        "        n_done = 0\n",
        "        while n_done < num_fakes:\n",
        "            cur_bs = min(batch_size, num_fakes - n_done)\n",
        "            z = torch.randn(cur_bs, nz, 1, 1, device=device)\n",
        "            fake_imgs = netG(z)  # salida en [-1,1] asumida\n",
        "            imgs_uint8 = _images_to_uint8(fake_imgs)  # numpy HWC uint8\n",
        "            imgs_t = torch.from_numpy(imgs_uint8.astype(np.float32) / 255.0).permute(0,3,1,2)\n",
        "            feats = fid_inception(imgs_t.to(device)).cpu().numpy()\n",
        "            feat_fake.append(feats)\n",
        "            n_done += cur_bs\n",
        "    netG.train()\n",
        "    feat_fake = np.vstack(feat_fake)\n",
        "    return feat_fake\n",
        "\n",
        "# Wrapper para integrarlo en calculate_metrics o en el loop de checkpoints\n",
        "def calculate_kid_stylegan(real_dataloader, netG, opt, cache_name=\"inception_feats_real.pkl\",\n",
        "                           num_fakes=None, num_subsets=100, max_subset_size=1000):\n",
        "    \"\"\"\n",
        "    Realiza KID fiel a StyleGAN2-ADA:\n",
        "    - cachea feats reales en opt.checkpoint_dir/cache_name\n",
        "    - genera num_fakes (por defecto = len(feat_real))\n",
        "    - aplica compute_kid con num_subsets, max_subset_size\n",
        "    \"\"\"\n",
        "    cache_file = os.path.join(opt.checkpoint_dir, cache_name)\n",
        "    # Obtener feats reales (cache)\n",
        "    feat_real = compute_and_cache_real_feats(real_dataloader, cache_file, max_reals=None)\n",
        "    if num_fakes is None:\n",
        "        num_fakes = feat_real.shape[0]\n",
        "\n",
        "    # Generar feats fake\n",
        "    feat_fake = compute_fake_feats_from_generator(netG, num_fakes=num_fakes,\n",
        "                                                 batch_size=opt.batchSize, nz=opt.nz, device=device)\n",
        "    # Calcular KID\n",
        "    kid_val = compute_kid(feat_real, feat_fake, num_subsets=num_subsets, max_subset_size=max_subset_size)\n",
        "    return kid_val\n",
        "\n",
        "\n",
        "# ================= MAIN =================\n",
        "if __name__ == '__main__':\n",
        "    opt = argsget()\n",
        "\n",
        "    # === Directorios ===\n",
        "    base_dir = opt.experiment\n",
        "    checkpoint_root = os.path.join(base_dir, \"CheckpointsE1\")\n",
        "    generated_root = os.path.join(base_dir, \"generatedE1\")\n",
        "    record_dir = os.path.join(base_dir, \"record\")\n",
        "\n",
        "    mkdir(checkpoint_root)\n",
        "    mkdir(generated_root)\n",
        "    mkdir(record_dir)\n",
        "\n",
        "    # Exponer rutas en opt para usarlas m√°s abajo\n",
        "    opt.generated_dir = generated_root\n",
        "\n",
        "    # === Manejo de sesiones de checkpoints (crea nueva carpeta cada vez) ===\n",
        "    existing_sessions = [d for d in os.listdir(checkpoint_root) if d.endswith(\"_checkpoint\")]\n",
        "    existing_sessions.sort()\n",
        "\n",
        "    resume_dir = None\n",
        "    start_epoch = 0\n",
        "\n",
        "\n",
        "    # === Archivos de historial global ===\n",
        "    loss_file = os.path.join(base_dir, \"loss_history.json\")\n",
        "    if os.path.exists(loss_file):\n",
        "        with open(loss_file, \"r\") as f:\n",
        "            loss_history = json.load(f)\n",
        "    else:\n",
        "        loss_history = []\n",
        "\n",
        "\n",
        "    # === Random seed ===\n",
        "    opt.manualSeed = random.randint(1, 10000)\n",
        "    print(f\"üé≤ Random Seed: {opt.manualSeed}\")\n",
        "\n",
        "    random.seed(opt.manualSeed)\n",
        "    torch.manual_seed(opt.manualSeed)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    dataloader = dstget(opt)  \n",
        "\n",
        "    # === Definir modelos\n",
        "    if opt.noBN:\n",
        "        netG = DCGAN_G_nobn(opt.img_size, opt.nz, opt.nc, opt.ngf, opt.ngpu, opt.n_extra_layers)\n",
        "    elif opt.mlp_G:\n",
        "        netG = MLP_G(opt.img_size, opt.nz, opt.nc, opt.ngf, opt.ngpu)\n",
        "    else:\n",
        "        netG = DCGAN_G(opt.img_size, opt.nz, opt.nc, opt.ngf, opt.ngpu, opt.n_extra_layers)\n",
        "    netG.apply(weights_init)\n",
        "    netG.to(device)\n",
        "\n",
        "    if opt.mlp_D:\n",
        "        netD = MLP_D(opt.img_size, opt.nz, opt.nc, opt.ndf, opt.ngpu)\n",
        "    else:\n",
        "        netD = DCGAN_D(opt.img_size, opt.nz, opt.nc, opt.ndf, opt.ngpu, opt.n_extra_layers)\n",
        "    netD.apply(weights_init)\n",
        "    netD.to(device)\n",
        "\n",
        "    # === Reanudar desde el √∫ltimo checkpoint consistente (G y D del mismo epoch) ===\n",
        "    if existing_sessions:\n",
        "        # Carpeta m√°s reciente (para reanudar)\n",
        "        last_session = existing_sessions[-1]\n",
        "        resume_dir = os.path.join(checkpoint_root, last_session)\n",
        "        print(f\"‚úÖ Carpeta de checkpoints encontrada: {resume_dir}\")\n",
        "\n",
        "        # Buscar checkpoints de esa carpeta\n",
        "        netG_files = glob.glob(os.path.join(resume_dir, \"netG_epoch*.pth\"))\n",
        "        netD_files = glob.glob(os.path.join(resume_dir, \"netD_epoch*.pth\"))\n",
        "\n",
        "        def extract_epochs(files, prefix):\n",
        "            epochs = []\n",
        "            for f in files:\n",
        "                m = re.search(rf\"{prefix}_epoch(\\d+)\\.pth\", os.path.basename(f))\n",
        "                if m:\n",
        "                    epochs.append(int(m.group(1)))\n",
        "            return sorted(epochs)\n",
        "\n",
        "        G_epochs = extract_epochs(netG_files, \"netG\")\n",
        "        D_epochs = extract_epochs(netD_files, \"netD\")\n",
        "        common_epochs = sorted(set(G_epochs).intersection(D_epochs))\n",
        "\n",
        "        if common_epochs:\n",
        "            start_epoch = common_epochs[-1]\n",
        "            netG.load_state_dict(torch.load(os.path.join(resume_dir, f\"netG_epoch{start_epoch}.pth\"), map_location=device))\n",
        "            netD.load_state_dict(torch.load(os.path.join(resume_dir, f\"netD_epoch{start_epoch}.pth\"), map_location=device))\n",
        "            print(f\"üîÑ Reanudando desde checkpoint epoch {start_epoch} en {resume_dir}\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è No se encontraron checkpoints coincidentes. Entrenamiento iniciar√° desde epoch 0.\")\n",
        "\n",
        "        # Crear NUEVA carpeta numerada\n",
        "        last_idx = int(last_session.split(\"_\")[0])\n",
        "        new_idx = last_idx + 1\n",
        "    else:\n",
        "        print(\"üÜï No hab√≠a checkpoints previos. Entrenamiento desde cero.\")\n",
        "        new_idx = 0\n",
        "\n",
        "    session_name = f\"{new_idx:05d}_checkpoint\"\n",
        "    opt.checkpoint_dir = os.path.join(checkpoint_root, session_name)\n",
        "    mkdir(opt.checkpoint_dir)\n",
        "    print(f\"üìÇ Nueva carpeta de checkpoints creada: {opt.checkpoint_dir}\")\n",
        "\n",
        "    # === Inputs fijos\n",
        "    noise = torch.FloatTensor(opt.batchSize, opt.nz, 1, 1).to(device)\n",
        "    fixed_noise = torch.FloatTensor(1, opt.nz, 1, 1).normal_(0, 1).to(device)  # solo 1 imagen\n",
        "\n",
        "    # === Optimizadores\n",
        "    if opt.adam:\n",
        "        optimizerD = optim.Adam(netD.parameters(), lr=opt.lrD, betas=(opt.beta1, 0.999))\n",
        "        optimizerG = optim.Adam(netG.parameters(), lr=opt.lrG, betas=(opt.beta1, 0.999))\n",
        "    else:\n",
        "        optimizerD = optim.RMSprop(netD.parameters(), lr=opt.lrD)\n",
        "        optimizerG = optim.RMSprop(netG.parameters(), lr=opt.lrG)\n",
        "\n",
        "    gen_iterations = 0\n",
        "    total_D, total_G = 0, 0\n",
        "    T1, T2 = opt.T1, opt.T2\n",
        "\n",
        "    # === Guardar imagen inicial SOLO si empezamos desde epoch 0 ===\n",
        "    if start_epoch == 0:\n",
        "        with torch.no_grad():\n",
        "            init_fake = netG(fixed_noise).detach()\n",
        "        save_image((init_fake.cpu() * 0.5 + 0.5),\n",
        "                  os.path.join(opt.generated_dir, \"generated_0.png\"),\n",
        "                  nrow=1, normalize=False)\n",
        "        print(\"üñºÔ∏è Imagen inicial generada guardada como generated_0.png\")\n",
        "\n",
        "\n",
        "    # === Entrenamiento\n",
        "    for epoch in range(start_epoch, opt.niter):\n",
        "        data_iter = iter(dataloader)\n",
        "        i = 0\n",
        "        while i < len(dataloader):\n",
        "            if gen_iterations < 2:  # WGAN warmup\n",
        "                Diters = 100\n",
        "                j = 0\n",
        "                while j < Diters and i < len(dataloader):\n",
        "                    j += 1\n",
        "                    total_D += 1\n",
        "                    imgs, _ = next(data_iter)\n",
        "                    imgs = imgs.to(device)\n",
        "                    i += 1\n",
        "                    errD_real, errD_fake, errD = discriminator_train(netD, netG, imgs, noise, optimizerD, opt)\n",
        "\n",
        "                total_G += 1\n",
        "                for p in netD.parameters():\n",
        "                    p.requires_grad = False\n",
        "                errG = generator_train(netG, netD, noise, optimizerG, opt)\n",
        "                gen_iterations += 1\n",
        "            else:  # AdaGAN mode\n",
        "                imgs, _ = next(data_iter)\n",
        "                imgs = imgs.to(device)\n",
        "                i += 1\n",
        "\n",
        "                c_errD_real, c_errD_fake, c_errD = discriminator_infer(netD, netG, imgs, noise, opt)\n",
        "                c_errG = c_errD_fake.item()\n",
        "\n",
        "                if not (c_errD_real.item() < c_errD_fake.item() - T2 and c_errG > T1):\n",
        "                    total_D += 1\n",
        "                    errD_real, errD_fake, errD = discriminator_train(netD, netG, imgs, noise, optimizerD, opt)\n",
        "                else:\n",
        "                    total_G += 1\n",
        "                    for p in netD.parameters():\n",
        "                        p.requires_grad = False\n",
        "                    errG = generator_train(netG, netD, noise, optimizerG, opt)\n",
        "                    gen_iterations += 1\n",
        "\n",
        "        # === Guardar p√©rdidas cada √©poca + imprimir progreso ===\n",
        "        epoch_losses = {\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"loss_D\": float(errD.item()) if 'errD' in locals() else None,\n",
        "            \"loss_G\": float(errG.item()) if 'errG' in locals() else None\n",
        "        }\n",
        "        loss_history.append(epoch_losses)\n",
        "        with open(loss_file, \"w\") as f:\n",
        "            json.dump(loss_history, f, indent=4)\n",
        "\n",
        "        d_str = f\"{epoch_losses['loss_D']:.4f}\" if epoch_losses['loss_D'] is not None else \"nan\"\n",
        "        g_str = f\"{epoch_losses['loss_G']:.4f}\" if epoch_losses['loss_G'] is not None else \"nan\"\n",
        "        print(f\"[√âpoca {epoch+1}/{opt.niter}] Loss_D: {d_str} | Loss_G: {g_str}\")\n",
        "\n",
        "        # === Guardar checkpoints, im√°genes y m√©tricas cada 5 √©pocas ===\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            # Guardar modelos\n",
        "            torch.save(netG.state_dict(), os.path.join(opt.checkpoint_dir, f\"netG_epoch{epoch+1}.pth\"))\n",
        "            torch.save(netD.state_dict(), os.path.join(opt.checkpoint_dir, f\"netD_epoch{epoch+1}.pth\"))\n",
        "\n",
        "            # Generar UNA imagen de ejemplo (fixed_noise)\n",
        "            with torch.no_grad():\n",
        "                fake_example = netG(fixed_noise).detach()\n",
        "            save_image((fake_example.cpu() * 0.5 + 0.5),\n",
        "                       os.path.join(opt.generated_dir, f\"generated_{epoch+1}.png\"),\n",
        "                       nrow=1, normalize=False)\n",
        "\n",
        "            # Ahora (ejemplo): calcula KID \"global\" usando todo el dataset y generador\n",
        "            kid_val = calculate_kid_stylegan(dataloader, netG, opt, cache_name=\"inception_feats_real.pkl\", num_fakes=min(10000, len(dataloader)*opt.batchSize), num_subsets=100, max_subset_size=1000)\n",
        "\n",
        "            # Calcular m√©tricas sobre un batch real y batch fake del mismo tama√±o\n",
        "            real_batch, _ = next(iter(dataloader))\n",
        "            real_batch = real_batch.to(device)\n",
        "            z = torch.randn(real_batch.size(0), opt.nz, 1, 1, device=device)\n",
        "            fake_batch = netG(z)\n",
        "            other_metrics = calculate_metrics(real_batch, fake_batch)  # esta funci√≥n ya devuelve FID etc.\n",
        "\n",
        "            metrics = calculate_metrics(real_batch, fake_batch)\n",
        "            metrics = {\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"KID\": kid_val,\n",
        "                \"FID\": other_metrics[\"FID\"],\n",
        "                \"LPIPS\": other_metrics[\"LPIPS\"],\n",
        "                \"SSIM\": other_metrics[\"SSIM\"],\n",
        "                \"PSNR\": other_metrics[\"PSNR\"],\n",
        "                \"JSD\": other_metrics[\"JSD\"]\n",
        "            }\n",
        "\n",
        "            # Guardar m√©tricas acumuladas\n",
        "            metrics_file = os.path.join(opt.checkpoint_dir, \"metrics_history.json\")\n",
        "            if os.path.exists(metrics_file):\n",
        "                with open(metrics_file, \"r\") as f:\n",
        "                    metrics_history = json.load(f)\n",
        "            else:\n",
        "                metrics_history = []\n",
        "            metrics_history.append(metrics)\n",
        "            with open(metrics_file, \"w\") as f:\n",
        "                json.dump(metrics_history, f, indent=4)\n",
        "\n",
        "            print(f\"‚úÖ Checkpoint, imagen y m√©tricas guardadas en √©poca {epoch+1} ‚Äî Carpeta: {opt.checkpoint_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR4LePFDkhwu"
      },
      "outputs": [],
      "source": [
        "# Ruta base \n",
        "base_dir = EXPERIMENTS_DIR\n",
        "\n",
        "# Archivos globales de p√©rdidas\n",
        "loss_file = os.path.join(base_dir, \"loss_history.json\")\n",
        "\n",
        "# Carpeta ra√≠z de checkpoints\n",
        "checkpoint_root = os.path.join(base_dir, \"CheckpointsE1\")\n",
        "\n",
        "# --- Cargar p√©rdidas ---\n",
        "loss_history = []\n",
        "if os.path.exists(loss_file):\n",
        "    with open(loss_file, \"r\") as f:\n",
        "        loss_history = json.load(f)\n",
        "df_loss = pd.DataFrame(loss_history)\n",
        "\n",
        "# --- Cargar TODAS las m√©tricas de todos los checkpoints ---\n",
        "metrics_history = []\n",
        "if os.path.exists(checkpoint_root):\n",
        "    sessions = [d for d in os.listdir(checkpoint_root) if d.endswith(\"_checkpoint\")]\n",
        "    sessions.sort()\n",
        "    for session in sessions:\n",
        "        metrics_file = os.path.join(checkpoint_root, session, \"metrics_history.json\")\n",
        "        if os.path.exists(metrics_file):\n",
        "            with open(metrics_file, \"r\") as f:\n",
        "                metrics = json.load(f)\n",
        "                metrics_history.extend(metrics)\n",
        "\n",
        "df_metrics = pd.DataFrame(metrics_history)\n",
        "\n",
        "# --- Merge p√©rdidas + m√©tricas ---\n",
        "df = pd.merge(df_loss, df_metrics, on=\"epoch\", how=\"outer\").sort_values(\"epoch\")\n",
        "\n",
        "# --- Reordenar columnas ---\n",
        "ordered_cols = [\"epoch\", \"loss_G\", \"loss_D\", \"FID\", \"KID\", \"JSD\", \"SSIM\", \"PSNR\", \"LPIPS\"]\n",
        "for col in ordered_cols:\n",
        "    if col not in df.columns:\n",
        "        df[col] = None\n",
        "\n",
        "df = df[ordered_cols]\n",
        "\n",
        "# --- Reemplazar NaN con vac√≠o ---\n",
        "df = df.fillna(\"\")\n",
        "\n",
        "# --- Guardar CSV ---\n",
        "csv_path = os.path.join(base_dir, \"metrics_medganE4.csv\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ CSV exportado en: {csv_path}\")\n",
        "df.tail()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "et8khyFu7x01",
        "O3ME2f1f-_Z3",
        "ggpYlaSK_ktK",
        "OKcTNp56zeyT"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
