{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TXIzZrPUjea"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "\n",
        "import os, glob, json, re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import skimage.metrics\n",
        "import lpips\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "PROJECT_ROOT = Path.cwd().parent\n",
        "STYLEGAN2_ADA_DIR = PROJECT_ROOT / \"external\" / \"stylegan2-ada\"\n",
        "sys.path.append(str(STYLEGAN2_ADA_DIR))\n",
        "import dnnlib\n",
        "import legacy\n",
        "\n",
        "# Definir el dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0tXlRW1Wkzbn"
      },
      "outputs": [],
      "source": [
        "PROJECT_ROOT = os.path.abspath(\"..\")  # si el notebook está en notebooks/\n",
        "REPO_DIR = os.path.join(PROJECT_ROOT, \"external\", \"stylegan2-ada\")\n",
        "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\", \"processed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYPV4tWmU5Fr",
        "outputId": "8679e93e-8011-4071-9ca8-b957bb38f263"
      },
      "outputs": [],
      "source": [
        "# DATASET\n",
        "DATASET_ZIP = os.path.join(DATA_DIR, \"frames_extraidos.zip\")\n",
        "assert os.path.isfile(DATASET_ZIP)\n",
        "RESULTS_DIR = os.path.join(REPO_DIR, \"results\", \"experiment_E2\")\n",
        "PROGRESS_DIR = os.path.join(REPO_DIR, \"progress\", \"experiment_E2\")\n",
        "\n",
        "os.makedirs(PROGRESS_DIR, exist_ok=True)\n",
        "\n",
        "# Buscar último snapshot\n",
        "snapshots = sorted(\n",
        "    glob.glob(os.path.join(RESULTS_DIR, \"0*/network-snapshot-*.pkl\"))\n",
        ")\n",
        "\n",
        "resume_path = snapshots[-1] if snapshots else None\n",
        "use_resume = True\n",
        "\n",
        "if use_resume and resume_path:\n",
        "    print(f\"Resuming from: {resume_path}\")\n",
        "else:\n",
        "    print(\"Training from scratch\")\n",
        "    resume_path = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1m_LCIQOypQ",
        "outputId": "71cdb5e3-b7c0-4fb5-f04e-ec7e418ace62"
      },
      "outputs": [],
      "source": [
        "cmd = [\n",
        "    \"python\", \"train.py\",\n",
        "    f\"--outdir={RESULTS_DIR}\",\n",
        "    f\"--data={DATASET_ZIP}\",\n",
        "    \"--gpus=1\",\n",
        "    \"--batch=32\",\n",
        "    \"--cfg=11gb-gpu\",\n",
        "    \"--mirror=0\",\n",
        "    \"--gamma=32\",\n",
        "    \"--aug=ada\",\n",
        "    \"--target=0.6\",\n",
        "    \"--lrate=0.006\",\n",
        "    \"--snap=4\"\n",
        "]\n",
        "\n",
        "if resume_path:\n",
        "    cmd.append(f\"--resume={resume_path}\")\n",
        "\n",
        "subprocess.run(cmd, check=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62TS1tDXPLG0"
      },
      "source": [
        "## Calculation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5orT-FyJO4qG",
        "outputId": "885589bd-6981-495a-8d99-e18ca1acf27d"
      },
      "outputs": [],
      "source": [
        "# ================== KID HELPER ==================\n",
        "# InceptionV3 para FID/KID: usamos el penúltimo layer (pool3)\n",
        "inception = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1, transform_input=False)\n",
        "inception.fc = nn.Identity()  # quitamos la última capa de clasificación\n",
        "inception.eval().to(device)\n",
        "\n",
        "def get_inception_features(x):\n",
        "    # x debe estar en rango [-1, 1], lo pasamos a [0, 1] si es necesario\n",
        "    if x.min() < 0:\n",
        "        x = (x + 1) / 2\n",
        "    if x.shape[2] != 299 or x.shape[3] != 299:\n",
        "        x = torch.nn.functional.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "    with torch.no_grad():\n",
        "        feats = inception(x)  # ahora devuelve [B,2048]\n",
        "    return feats\n",
        "\n",
        "\n",
        "def polynomial_mmd(x, y, degree=3, gamma=None, coef0=1):\n",
        "    xx = x @ x.t()\n",
        "    yy = y @ y.t()\n",
        "    xy = x @ y.t()\n",
        "    if gamma is None:\n",
        "        gamma = 1.0 / x.shape[1]\n",
        "    K_xx = (gamma * xx + coef0) ** degree\n",
        "    K_yy = (gamma * yy + coef0) ** degree\n",
        "    K_xy = (gamma * xy + coef0) ** degree\n",
        "    return K_xx.mean() + K_yy.mean() - 2 * K_xy.mean()\n",
        "\n",
        "def compute_kid(real_imgs, fake_imgs, batch_size=16):\n",
        "    real_feats, fake_feats = [], []\n",
        "    for i in range(0, len(real_imgs), batch_size):\n",
        "        r = torch.cat(real_imgs[i:i+batch_size]).to(device)\n",
        "        f = torch.cat(fake_imgs[i:i+batch_size]).to(device)\n",
        "        real_feats.append(get_inception_features(r))\n",
        "        fake_feats.append(get_inception_features(f))\n",
        "    real_feats = torch.cat(real_feats, dim=0)\n",
        "    fake_feats = torch.cat(fake_feats, dim=0)\n",
        "    return polynomial_mmd(real_feats, fake_feats).item()\n",
        "\n",
        "\n",
        "# === PPL helper ===\n",
        "def compute_ppl(G, device, n_samples=64, eps=1e-4):\n",
        "    lat_dim = G.z_dim\n",
        "    z = torch.randn([n_samples, lat_dim], device=device)\n",
        "    c = torch.zeros([n_samples, G.c_dim], device=device)\n",
        "\n",
        "    # Interpolación en el espacio latente\n",
        "    z_eps = z.clone()\n",
        "    z_eps[:, 0] += eps  # perturbamos la primera dimensión del vector z\n",
        "\n",
        "    # Generar imágenes originales y perturbadas\n",
        "    imgs1 = G(z, c, truncation_psi=0.7, noise_mode='const')\n",
        "    imgs2 = G(z_eps, c, truncation_psi=0.7, noise_mode='const')\n",
        "\n",
        "    # Normalizamos [0,1] para LPIPS\n",
        "    imgs1 = (imgs1.clamp(-1, 1) + 1) / 2\n",
        "    imgs2 = (imgs2.clamp(-1, 1) + 1) / 2\n",
        "\n",
        "    # Redimensionamos a 256x256 para LPIPS (más rápido)\n",
        "    imgs1 = torch.nn.functional.interpolate(imgs1, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "    imgs2 = torch.nn.functional.interpolate(imgs2, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "\n",
        "    # LPIPS perceptual distance\n",
        "    lpips_model = lpips.LPIPS(net='alex').to(device)\n",
        "    d = lpips_model(imgs1, imgs2)\n",
        "\n",
        "    # Escalamos por la perturbación\n",
        "    ppl = (d / (eps**2)).mean().item()\n",
        "    return ppl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metrics CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wik06kl7PVNv"
      },
      "outputs": [],
      "source": [
        "# ================== CONFIGURACIÓN ==================\n",
        "# Dataset\n",
        "N_images = 40120\n",
        "mirror = 0          # 1 si usaste --mirror=1, 0 si no\n",
        "N_eff = N_images * (2 if mirror == 1 else 1)\n",
        "\n",
        "# Paths\n",
        "results_dir = \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/resultsE2\"\n",
        "progreso_dir = \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/progresoE2\"\n",
        "data_dir = \"/content/drive/MyDrive/Proyecto_Grado/Data\"\n",
        "os.makedirs(progreso_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Imagen real (ejemplo: primera de class0)\n",
        "real_image_path = sorted(glob.glob(f'{data_dir}/frames_extraidos/*.png'))[0]\n",
        "target_size = (512, 512)\n",
        "\n",
        "# Transformación\n",
        "real_img = Image.open(real_image_path).convert('RGB').resize(target_size)\n",
        "transform = T.ToTensor()\n",
        "x_real = transform(real_img).numpy()\n",
        "\n",
        "# CSV final\n",
        "out_csv = os.path.join(progreso_dir, \"metrics_snapshots.csv\")\n",
        "\n",
        "# ================== MÉTRICAS ==================\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# LPIPS\n",
        "loss_fn_lpips = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "# JSD helper\n",
        "def compute_jsd(p, q, bins=256):\n",
        "    p_hist, _ = np.histogram(p.flatten(), bins=bins, range=(0,1), density=True)\n",
        "    q_hist, _ = np.histogram(q.flatten(), bins=bins, range=(0,1), density=True)\n",
        "    return jensenshannon(p_hist, q_hist)\n",
        "\n",
        "# ================== LOOP PRINCIPAL ==================\n",
        "all_rows = []\n",
        "run_dirs = sorted(glob.glob(f'{results_dir}/0000*'))\n",
        "\n",
        "kimg_offset = 0  # <<< offset acumulativo de kimgs\n",
        "\n",
        "for run_dir in run_dirs:\n",
        "    run_id = os.path.basename(run_dir)\n",
        "\n",
        "    # ---- Cargar stats.jsonl para pérdidas ----\n",
        "    stats_path = os.path.join(run_dir, 'stats.jsonl')\n",
        "    stats_lines = []\n",
        "    if os.path.exists(stats_path):\n",
        "        with open(stats_path, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    e = json.loads(line)\n",
        "                    kimg_val = e['Progress/kimg']['mean'] if isinstance(e['Progress/kimg'], dict) else e['Progress/kimg']\n",
        "                    g_loss = e['Loss/G/loss']['mean'] if isinstance(e['Loss/G/loss'], dict) else e['Loss/G/loss']\n",
        "                    d_loss = e['Loss/D/loss']['mean'] if isinstance(e['Loss/D/loss'], dict) else e['Loss/D/loss']\n",
        "                    stats_lines.append((float(kimg_val), g_loss, d_loss))\n",
        "                except KeyError:\n",
        "                    continue\n",
        "\n",
        "    # ---- Cargar metric-fid50k_full.jsonl ----\n",
        "    fid_dict = {}\n",
        "    fid_path = os.path.join(run_dir, \"metric-fid50k_full.jsonl\")\n",
        "    if os.path.exists(fid_path):\n",
        "        with open(fid_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    e = json.loads(line)\n",
        "                    snap = os.path.basename(e[\"snapshot_pkl\"])\n",
        "                    fid = e[\"results\"][\"fid50k_full\"]\n",
        "                    fid_dict[snap] = fid\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    # ---- Buscar snapshots ----\n",
        "    snapshot_paths = sorted(glob.glob(f'{run_dir}/network-snapshot-*.pkl'))\n",
        "\n",
        "    for snapshot in snapshot_paths:\n",
        "        snap_name = os.path.basename(snapshot)\n",
        "        kimg_match = re.search(r'network-snapshot-(\\d+).pkl', snapshot)\n",
        "        if not kimg_match:\n",
        "            continue\n",
        "        kimg_snap_local = int(kimg_match.group(1))  # kimg relativo a la carpeta\n",
        "        kimg_snap = kimg_snap_local + kimg_offset   # kimg absoluto y continuo\n",
        "        epoch = (kimg_snap * 1000) / N_eff          # conversión a épocas\n",
        "\n",
        "        # Buscar pérdidas en stats.jsonl para este kimg local\n",
        "        g_loss, d_loss = None, None\n",
        "        if stats_lines:\n",
        "            nearest = min(stats_lines, key=lambda x: abs(x[0] - kimg_snap_local))\n",
        "            g_loss, d_loss = nearest[1], nearest[2]\n",
        "\n",
        "        # === Generar imagen con el snapshot ===\n",
        "        with dnnlib.util.open_url(snapshot) as f_model:\n",
        "            G = legacy.load_network_pkl(f_model)['G_ema'].to(device)\n",
        "\n",
        "        z = torch.randn([1, G.z_dim], device=device)\n",
        "        label = torch.zeros([1, G.c_dim], device=device)\n",
        "        img = G(z, label, truncation_psi=0.7, noise_mode='const')\n",
        "\n",
        "        img = (img.clamp(-1, 1) + 1) * 127.5\n",
        "        img = img.permute(0, 2, 3, 1)[0].cpu().numpy().astype(np.uint8)\n",
        "        if img.shape[-1] == 1:\n",
        "            img = np.repeat(img, 3, axis=-1)\n",
        "\n",
        "        img_pil = Image.fromarray(img).resize(target_size)\n",
        "\n",
        "        # === Calcular métricas SSIM y PSNR ===\n",
        "        x_fake = transform(img_pil).numpy()\n",
        "        ssim_val = skimage.metrics.structural_similarity(\n",
        "            x_real.transpose(1, 2, 0),\n",
        "            x_fake.transpose(1, 2, 0),\n",
        "            channel_axis=-1,\n",
        "            data_range=1.0\n",
        "        )\n",
        "        psnr_val = skimage.metrics.peak_signal_noise_ratio(\n",
        "            x_real, x_fake, data_range=1.0\n",
        "        )\n",
        "\n",
        "        # === LPIPS ===\n",
        "        x_real_torch = torch.tensor(x_real).unsqueeze(0).to(device)\n",
        "        x_fake_torch = torch.tensor(x_fake).unsqueeze(0).to(device)\n",
        "        lpips_val = loss_fn_lpips(x_real_torch, x_fake_torch).item()\n",
        "\n",
        "        # === JSD ===\n",
        "        jsd_val = compute_jsd(x_real, x_fake)\n",
        "\n",
        "        # === FID (si existe en metric-fid50k_full.jsonl) ===\n",
        "        fid_val = fid_dict.get(snap_name, None)\n",
        "\n",
        "        # === KID ===\n",
        "        # Normalizar imágenes a [0,1] y tensor 3xHxW\n",
        "        x_real_torch_incep = x_real_torch.clone()\n",
        "        x_fake_torch_incep = x_fake_torch.clone()\n",
        "        kid_val = compute_kid(\n",
        "            [x_real_torch.cpu()],\n",
        "            [x_fake_torch.cpu()]\n",
        "        )\n",
        "\n",
        "        # === PPL ===\n",
        "        ppl_val = compute_ppl(G, device, n_samples=64, eps=1e-4)\n",
        "\n",
        "        # === Guardar fila ===\n",
        "        all_rows.append([\n",
        "          epoch, g_loss, d_loss, fid_val, kid_val, ssim_val, psnr_val,\n",
        "          lpips_val, jsd_val, ppl_val, kimg_snap, run_id\n",
        "      ])\n",
        "\n",
        "    # ---- Actualizar offset con el último snapshot de esta carpeta ----\n",
        "    if snapshot_paths:\n",
        "        last_local = max(int(re.search(r'network-snapshot-(\\d+).pkl', s).group(1)) for s in snapshot_paths)\n",
        "        kimg_offset += last_local  # se suma al offset global\n",
        "\n",
        "# ================== GUARDAR CSV ==================\n",
        "df_all = pd.DataFrame(all_rows, columns=[\n",
        "    'epoch', 'G_loss', 'D_loss', 'FID', 'KID', 'SSIM', 'PSNR',\n",
        "    'LPIPS', 'JSD', 'PPL', 'kimg', 'run_id'\n",
        "])\n",
        "df_all = df_all.sort_values(['kimg'])\n",
        "df_all.to_csv(out_csv, index=False)\n",
        "print(f\"CSV final con snapshots guardado en: {out_csv}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generated Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl64GUxGPXv3"
      },
      "outputs": [],
      "source": [
        "# Número de imágenes en tu dataset\n",
        "N_images = 40120   # cámbialo si tu dataset cambia\n",
        "mirror = 0         # ponlo en 1 si usaste --mirror=1\n",
        "N_eff = N_images * (2 if mirror == 1 else 1)\n",
        "\n",
        "# Ruta donde están los resultados\n",
        "results_dir = \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/resultsE2\"\n",
        "progreso_dir = \"/content/drive/MyDrive/Proyecto_Grado/colab-sg2-ada-pytorch/progresoE2\"\n",
        "os.makedirs(progreso_dir, exist_ok=True)\n",
        "\n",
        "# Inicializar lista de DataFrames\n",
        "all_runs_data = []\n",
        "\n",
        "# Buscar todas las carpetas de runs\n",
        "run_dirs = sorted(glob.glob(f'{results_dir}/0000*'))\n",
        "\n",
        "# Offset acumulado de kimg\n",
        "kimg_offset = 0\n",
        "\n",
        "for run_dir in run_dirs:\n",
        "    run_id = os.path.basename(run_dir)\n",
        "\n",
        "    stats_path = os.path.join(run_dir, 'stats.jsonl')\n",
        "    if not os.path.exists(stats_path):\n",
        "        print(f\"Stats no encontrado para {run_id}, se omite.\")\n",
        "        continue\n",
        "\n",
        "    # Leer cada línea JSON\n",
        "    with open(stats_path, 'r') as f:\n",
        "        lines = [json.loads(line) for line in f]\n",
        "\n",
        "    rows = []\n",
        "    for entry in lines:\n",
        "        try:\n",
        "            kimg = entry['Progress/kimg']['mean'] if isinstance(entry['Progress/kimg'], dict) else entry['Progress/kimg']\n",
        "            g_loss = entry['Loss/G/loss']['mean'] if isinstance(entry['Loss/G/loss'], dict) else entry['Loss/G/loss']\n",
        "            d_loss = entry['Loss/D/loss']['mean'] if isinstance(entry['Loss/D/loss'], dict) else entry['Loss/D/loss']\n",
        "\n",
        "            # Calcular kimg acumulado\n",
        "            kimg_total = kimg + kimg_offset\n",
        "\n",
        "            # Convertir a épocas\n",
        "            epoch = (kimg_total * 1000) / N_eff\n",
        "\n",
        "            # Guardar fila\n",
        "            rows.append({\n",
        "                'epoch': epoch,         # columna 1: épocas acumuladas\n",
        "                'G_loss': g_loss,       # columna 2\n",
        "                'D_loss': d_loss,       # columna 3\n",
        "                'kimg': kimg_total,     # columna 4: kimg acumulado\n",
        "                'run_id': run_id        # columna 5: carpeta origen\n",
        "            })\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "    # Si se recogieron datos en este run\n",
        "    if rows:\n",
        "        df_run = pd.DataFrame(rows)\n",
        "        all_runs_data.append(df_run)\n",
        "\n",
        "        # Actualizar offset: sumar el último kimg de esta carpeta\n",
        "        last_kimg = df_run['kimg'].max() - kimg_offset  # solo lo local\n",
        "        kimg_offset += last_kimg\n",
        "\n",
        "# Combinar todos los runs en un solo DataFrame\n",
        "df_all = pd.concat(all_runs_data, ignore_index=True)\n",
        "\n",
        "# Guardar como CSV\n",
        "out_csv = os.path.join(progreso_dir, 'losses_all_runs.csv')\n",
        "df_all.to_csv(out_csv, index=False)\n",
        "print(f\"CSV combinado guardado en: {out_csv}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
