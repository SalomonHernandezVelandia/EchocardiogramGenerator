# Echocardiogram Image Generation using Generative Learning Strategies

<p align="center">
  <img src="assets/generated_stylegan.gif" width="100%"/>
</p>

[![Python](https://img.shields.io/badge/Python-3.10+-2E7D32?logo=python&logoColor=white)]
[![Jupyter Notebook](https://img.shields.io/badge/Jupyter-Notebook-F57C00?logo=jupyter&logoColor=white)]
[![Deep Learning](https://img.shields.io/badge/Deep%20Learning-Neural%20Networks-6A1B9A)]
[![PyTorch](https://img.shields.io/badge/PyTorch-Framework-EE4C2C?logo=pytorch&logoColor=white)]


## Related Publications

### Conference Paper (IEEE SIPAIM)

**Comparative Study of Methods for Generating Echocardiographic Images**  
S. HernÃ¡ndez, et al.  
SIPAIM, IEEE, 2025  

<p align="center">  

  <a href="https://ieeexplore.ieee.org/document/11283212">
    <img src="https://img.shields.io/badge/IEEE-Xplore-00629B" alt="IEEE Xplore">
  </a>

  <a href="https://doi.org/10.1109/SIPAIM67325.2025.11283212">
    <img src="https://img.shields.io/badge/DOI-10.1109%2FSIPAIM67325.2025.11283212-555555" alt="DOI">
  </a>

  <a href="https://www.researchgate.net/publication/398847593">
    <img src="https://img.shields.io/badge/Preprint-ResearchGate-00CCBB?logo=researchgate" alt="ResearchGate Preprint">
  </a>
</p>

> This article represents the first and most concise version of the research, presenting the results of StyleGAN and MedGAN as generation architectures alongside VQGAN and Pix2Pix as reconstruction architectures. 

### Thesis (Extended and Robust Study)

**GeneraciÃ³n de imÃ¡genes de ecocardiogramas mediante estrategias de aprendizaje generativo**  
SalomÃ³n HernÃ¡ndez Velandia  
(Thesis manuscript â€“ not yet formally published)

> The thesis significantly extends the SIPAIM publication by incorporating additional architectures, deeper experimental analysis, and a more comprehensive evaluation framework.

A preprint version of the thesis is available in the `publications/thesis/` directory.

---

## Table of Contents

- [Echocardiogram Image Generation using Generative Learning Strategies](#echocardiogram-image-generation-using-generative-learning-strategies)
  - [Related Publications](#related-publications)
  - [Table of Contents](#table-of-contents)
  - [Tech Stack](#tech-stack)
  - [Research Context](#research-context)
  - [Thesis (Extended and Robust Study)](#thesis-extended-and-robust-study)


## Tech Stack

This repository contains the code, experimental setup, and results associated with the research project:

**"GeneraciÃ³n de imÃ¡genes de ecocardiogramas mediante estrategias de aprendizaje generativo"**

This work was developed as a thesis project and extends previous research published at SIPAIM (IEEE), exploring multiple generative architectures for synthetic echocardiographic image generation.

---


## Research Context

The generation of synthetic echocardiographic images is an effective alternative for data augmentation, avoiding the limitations of traditional data augmentation techniques such as affine transformations, which can alter, distort, or falsify medical images and cause critical spatial errors. By using generative models such as GANs, it is possible to create entirely new and diverse images that preserve anatomical and morphological properties, facilitating the comparative evaluation of algorithms and the study of reproducibility in this field of medical imaging.

This project presents a comprehensive comparative study of different generative architectures applied to apical four-chamber echocardiography, the objective is to expand and diversify the available datasets, identify the most efficient model and configuration for generating new images, and thus enrich the resources dedicated to the analysis of cardiac function.

### The architectures explored include:
- StyleGAN2-ADA
- MedGAN
- WGAN
- VQGAN

Each architecture was evaluated under eight different hyperparameter configurations and training strategies, the process included preprocessing the Echonet-Dynamic dataset, which consisted of converting it to grayscale, resizing it to 128Ã—128 pixels, leveraging a power of 2 to optimize calculations in the GANs, binarization to extract the frames corresponding to diastole and systole for each patient, and selecting the first and last frames of each sequence to diversify the training data. All of this processing can be found in `src/preprocessing/extractionframes.py`

---

## Implemented Configurations

| Architecture | FID Curve |
|-------------|----------|
| **StyleGAN2-ADA** | [View Image](results/stylegan2-ada/line_graph/FID_stylegan2ada.png) |
| **MedGAN** | [View Image](results/medgan/line_graph/FID_medgan.png) |
| **WGAN** | [View Image](results/wgan/line_graph/FID_wgan.png) |
| **VQGAN** | [View Image](results/vqgan/line_graph/FID_vqgan.png) |



<h3 align="center">FID Comparison</h3>

<p align="center">
  <img src="results/stylegan2_ada/line_graph/FID_style.png" width="350">
  <img src="results/medgan/line_graph/FID_medgan.png" width="350">
  <img src="results/wgan/line_graph/FID_wgan.png" width="350">
  <img src="results/vqgan/line_graph/FID_vqgan.png" width="350">
</p>

---


<p align="center">  <!-- GitHub Repo -->
  <!-- <a href="https://github.com/SalomonHernandezVelandia/EchocardiogramGenerator">
    <img src="https://img.shields.io/badge/GitHub-Repository-181717?logo=github" alt="GitHub Repository">
  </a> -->

  <!-- LinkedIn -->
  <a href="https://www.linkedin.com/in/salomon-hernandez-velandia-827417196/">
    <img src="https://img.shields.io/badge/LinkedIn-Salomon_Hernandez-0A66C2?logo=linkedin" alt="LinkedIn Profile">
  </a>
</p>

## ğŸ—‚ï¸ Repository Structure

```text
ecocardiogram-gan-thesis/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ LICENSE_DATA
â”œâ”€â”€ CITATION.cff
â”œâ”€â”€ requirements.txt
|
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ stylegan2_ada/
â”‚   â”‚   â”œâ”€â”€ E1/
â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ .....pth
â”‚   â”‚   â”‚   â”œâ”€â”€ generated_samples/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ generated_0.png
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ generated_25.png
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics_csv/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.csv
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ losses.csv
â”‚   â”‚   â”‚   â””â”€â”€ samples/
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ E2/
â”‚   â”‚   â”œâ”€â”€ E3/
â”‚   â”‚   â””â”€â”€ E4/
â”‚   â”‚
â”‚   â”œâ”€â”€ medgan/
â”‚   â”‚   â”œâ”€â”€ M1/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ wgan/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ vqgan/
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ external/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ stylegan2-ada/   # submodule o instrucciÃ³n de clonaciÃ³n
â”‚
â”œâ”€â”€ publications/
â”‚   â”œâ”€â”€ sipaim/
â”‚   â””â”€â”€ thesis/
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ StyleGan2_Ada.ipynb
â”‚   â”œâ”€â”€ MedGAN.ipynb
â”‚   â””â”€â”€ WGAN.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ medgan/
â”‚   â”‚   â”œâ”€â”€ dcgan.py
â”‚   â”‚   â”œâ”€â”€ mlp.py
â”‚   â”‚   â””â”€â”€ dztaset.py
â”‚   |
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ comprobacion_sistole.py
â”‚   â”‚   â”œâ”€â”€ convertirZIP.py
â”‚   â”‚   â”œâ”€â”€ extractionframes.py
â”‚   â”‚   â”œâ”€â”€ visualizacion_mask.py
â”‚   â”‚   â””â”€â”€ visualizacion_binarizacion.py
â”‚   â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ stylegan2_ada/
â”‚   |   â”œâ”€â”€ line_graph/
â”‚   |   â”œâ”€â”€ losses/
â”‚   |   â”œâ”€â”€ radar_graph/
â”‚   |   â””â”€â”€ violin_boxplot_graph/
â”‚   |
â”‚   â”œâ”€â”€ medgan/
â”‚   |   â”œâ”€â”€ line_graph/
â”‚   |   â”œâ”€â”€ losses/
â”‚   |   â”œâ”€â”€ radar_graph/
â”‚   |   â””â”€â”€ violin_boxplot_graph/
â”‚   |
â”‚   â”œâ”€â”€ wgan/
â”‚   |   â”œâ”€â”€ line_graph/
â”‚   |   â”œâ”€â”€ losses/
â”‚   |   â”œâ”€â”€ radar_graph/
â”‚   |   â””â”€â”€ violin_boxplot_graph/
â”‚   |
â”‚   â””â”€â”€ vqgan/
â”‚       â”œâ”€â”€ line_graph/
â”‚       â”œâ”€â”€ losses/
â”‚       â”œâ”€â”€ radar_graph/
â”‚       â””â”€â”€ violin_boxplot_graph/
â”‚   


â”œâ”€â”€ configs/                # Configuration files for different architectures and experiments
â”œâ”€â”€ generated_samples/      # Synthetic echocardiographic images
â”œâ”€â”€ checkpoints/            # Trained model checkpoints (if applicable)
â”œâ”€â”€ publications/           # Thesis and paper preprints
â”œâ”€â”€ external/               # External repositories (e.g., StyleGAN2-ADA, VQGAN)
â”œâ”€â”€ scripts/                # Utility scripts for setup, training, and evaluation
